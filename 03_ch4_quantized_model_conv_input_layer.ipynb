{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb10a1f",
   "metadata": {},
   "source": [
    "# Challenge 4 study - Quantized Model with Conv Input Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543e567",
   "metadata": {},
   "source": [
    "## Import libraries and data, init virtual device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c11ff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:23:11.491770: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-11 10:23:11.669317: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-11 10:23:11.669350: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-11 10:23:11.712468: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-11 10:23:12.670897: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-11 10:23:12.671020: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-11 10:23:12.671039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-11 10:23:13.655229: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-11 10:23:13.655284: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-11 10:23:13.655313: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (87c26121fd32): /proc/driver/nvidia/version does not exist\n",
      "2022-11-11 10:23:13.655643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, ReLU, Conv2D, Flatten, Dropout\n",
    "\n",
    "from akida import Device, AKD1000\n",
    "import cnn2snn\n",
    "\n",
    "device = AKD1000()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f448ce",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53acf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[221],\n",
       "        [221],\n",
       "        [221],\n",
       "        [210],\n",
       "        [210],\n",
       "        [210]],\n",
       "\n",
       "       [[221],\n",
       "        [221],\n",
       "        [221],\n",
       "        [210],\n",
       "        [210],\n",
       "        [210]],\n",
       "\n",
       "       [[221],\n",
       "        [221],\n",
       "        [221],\n",
       "        [210],\n",
       "        [210],\n",
       "        [210]],\n",
       "\n",
       "       [[221],\n",
       "        [221],\n",
       "        [221],\n",
       "        [210],\n",
       "        [210],\n",
       "        [210]],\n",
       "\n",
       "       [[221],\n",
       "        [221],\n",
       "        [221],\n",
       "        [210],\n",
       "        [210],\n",
       "        [210]],\n",
       "\n",
       "       [[221],\n",
       "        [221],\n",
       "        [221],\n",
       "        [210],\n",
       "        [210],\n",
       "        [210]]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_ch4 = np.load('coords_ch4.npy')\n",
    "color = np.load('result_ch4.npy')\n",
    "\n",
    "# Pack in a dataframe and scale for 8-bits quantization (first layer will be quantized on 8-bits)\n",
    "data = pd.DataFrame(coords_ch4, columns = ['x', 'y'])\n",
    "data = round(255*data).astype(np.uint8)\n",
    "\n",
    "\n",
    "# Shuffle and split train/test\n",
    "data['color'] = color\n",
    "data_train = data.sample(frac=0.7, axis=0)\n",
    "data_test = data.drop(data_train.index)\n",
    "\n",
    "# Split x y\n",
    "x_train = data_train.drop('color', axis=1)\n",
    "y_train = data_train['color']\n",
    "x_test = data_test.drop('color', axis=1)\n",
    "y_test = data_test['color']\n",
    "\n",
    "\n",
    "# Attempt to encode coordinates as an image: put the x value as grey scale on the left, then y on the right\n",
    "left = np.empty((6, 3))\n",
    "right = np.empty((6, 3))\n",
    "\n",
    "x_train_coded = np.empty((7000, 6, 6))\n",
    "for i, p in enumerate(x_train.to_numpy()):\n",
    "    left.fill(p[0])\n",
    "    right.fill(p[1])\n",
    "    x_train_coded[i] = np.concatenate((left, right), axis=1)\n",
    "x_train_coded = x_train_coded.reshape(-1, 6, 6, 1).astype(np.uint8)\n",
    "\n",
    "x_test_coded = np.empty((3000, 6, 6))\n",
    "for i, p in enumerate(x_test.to_numpy()):\n",
    "    left.fill(p[0])\n",
    "    right.fill(p[1])\n",
    "    x_test_coded[i] = np.concatenate((left, right), axis=1)\n",
    "x_test_coded = x_test_coded.reshape(-1, 6, 6, 1).astype(np.uint8)\n",
    "\n",
    "x_train_coded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc350f17",
   "metadata": {},
   "source": [
    "## Model creation with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Sequential(name=\"Base_ch4\")\n",
    "base.add(Conv2D(1, (3, 3), strides=(3, 3), input_shape=(6, 6, 1), name='C2D'))\n",
    "base.add(ReLU(name='relu0'))\n",
    "base.add(Dropout(0.2))\n",
    "base.add(Flatten())\n",
    "base.add(Dense(1000, name='FC1'))\n",
    "base.add(ReLU(name='relu1'))\n",
    "base.add(Dense(500, name='FC2'))\n",
    "base.add(ReLU(name='relu2'))\n",
    "base.add(Dense(250, name='FC3'))\n",
    "base.add(ReLU(name='relu3'))\n",
    "base.add(Dense(100, name='FC4'))\n",
    "base.add(ReLU(name='relu4'))\n",
    "base.add(Dense(50, name='FC5'))\n",
    "base.add(ReLU(name='relu5'))\n",
    "base.add(Dense(1, name='FC6'))\n",
    "base.add(Activation('sigmoid', name='sigmoid'))\n",
    "\n",
    "#base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43e0b4",
   "metadata": {},
   "source": [
    "## Model quantization (4-bits, input: 8-bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1390dddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " C2D (QuantizedConv2D)       (None, 2, 2, 1)           10        \n",
      "                                                                 \n",
      " relu0 (QuantizedReLU)       (None, 2, 2, 1)           0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 2, 1)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4)                 0         \n",
      "                                                                 \n",
      " FC1 (QuantizedDense)        (None, 1000)              5000      \n",
      "                                                                 \n",
      " relu1 (QuantizedReLU)       (None, 1000)              0         \n",
      "                                                                 \n",
      " FC2 (QuantizedDense)        (None, 500)               500500    \n",
      "                                                                 \n",
      " relu2 (QuantizedReLU)       (None, 500)               0         \n",
      "                                                                 \n",
      " FC3 (QuantizedDense)        (None, 250)               125250    \n",
      "                                                                 \n",
      " relu3 (QuantizedReLU)       (None, 250)               0         \n",
      "                                                                 \n",
      " FC4 (QuantizedDense)        (None, 100)               25100     \n",
      "                                                                 \n",
      " relu4 (QuantizedReLU)       (None, 100)               0         \n",
      "                                                                 \n",
      " FC5 (QuantizedDense)        (None, 50)                5050      \n",
      "                                                                 \n",
      " relu5 (QuantizedReLU)       (None, 50)                0         \n",
      "                                                                 \n",
      " FC6 (QuantizedDense)        (None, 1)                 51        \n",
      "                                                                 \n",
      " sigmoid (Activation)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 660,961\n",
      "Trainable params: 660,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Akida Compatibility: True\n"
     ]
    }
   ],
   "source": [
    "qmodel = cnn2snn.quantize(base, weight_quantization=4, activ_quantization=4, input_weight_quantization=8)\n",
    "qmodel.summary()\n",
    "\n",
    "print('\\nAkida Compatibility:', cnn2snn.check_model_compatibility(qmodel, input_is_image=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad8c8a",
   "metadata": {},
   "source": [
    "## Preview akida model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2c5bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model Summary                   \n",
      "___________________________________________________\n",
      "Input shape  Output shape  Sequences  Layers  NPs\n",
      "===================================================\n",
      "[6, 6, 1]    [1, 1, 1]     1          7       6  \n",
      "___________________________________________________\n",
      "\n",
      "________________________________________________________\n",
      "Layer (type)      Output shape  Kernel shape       NPs\n",
      "\n",
      "====== HW/C2D-FC6 (Hardware) - size: 560560 bytes ======\n",
      "\n",
      "C2D (InputConv.)  [2, 2, 1]     (3, 3, 1, 1)       N/A\n",
      "________________________________________________________\n",
      "FC1 (Fully.)      [1, 1, 1000]  (1, 1, 4, 1000)    1  \n",
      "________________________________________________________\n",
      "FC2 (Fully.)      [1, 1, 500]   (1, 1, 1000, 500)  1  \n",
      "________________________________________________________\n",
      "FC3 (Fully.)      [1, 1, 250]   (1, 1, 500, 250)   1  \n",
      "________________________________________________________\n",
      "FC4 (Fully.)      [1, 1, 100]   (1, 1, 250, 100)   1  \n",
      "________________________________________________________\n",
      "FC5 (Fully.)      [1, 1, 50]    (1, 1, 100, 50)    1  \n",
      "________________________________________________________\n",
      "FC6 (Fully.)      [1, 1, 1]     (1, 1, 50, 1)      1  \n",
      "________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "akmodel = cnn2snn.convert(qmodel, input_is_image=True)\n",
    "akmodel.map(device)\n",
    "akmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957d01f",
   "metadata": {},
   "source": [
    "## Train quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c9e56b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "110/110 [==============================] - 6s 27ms/step - loss: 0.7329 - accuracy: 0.5001\n",
      "Epoch 2/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.7063 - accuracy: 0.5020\n",
      "Epoch 3/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.7013 - accuracy: 0.5053\n",
      "Epoch 4/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.7069 - accuracy: 0.4986\n",
      "Epoch 5/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.7058 - accuracy: 0.4930\n",
      "Epoch 6/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.7041 - accuracy: 0.4951\n",
      "Epoch 7/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6993 - accuracy: 0.5131\n",
      "Epoch 8/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.7005 - accuracy: 0.5054\n",
      "Epoch 9/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6992 - accuracy: 0.5074\n",
      "Epoch 10/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.7032 - accuracy: 0.4950\n",
      "Epoch 11/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6978 - accuracy: 0.4996\n",
      "Epoch 12/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6990 - accuracy: 0.4896\n",
      "Epoch 13/600\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 0.6965 - accuracy: 0.5091\n",
      "Epoch 14/600\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 0.6964 - accuracy: 0.5030\n",
      "Epoch 15/600\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 0.6977 - accuracy: 0.4957\n",
      "Epoch 16/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6956 - accuracy: 0.4964\n",
      "Epoch 17/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6972 - accuracy: 0.4987\n",
      "Epoch 18/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6972 - accuracy: 0.5004\n",
      "Epoch 19/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6951 - accuracy: 0.5094\n",
      "Epoch 20/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6970 - accuracy: 0.5003\n",
      "Epoch 21/600\n",
      "110/110 [==============================] - 4s 40ms/step - loss: 0.6934 - accuracy: 0.5123\n",
      "Epoch 22/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6941 - accuracy: 0.4993\n",
      "Epoch 23/600\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 0.6956 - accuracy: 0.5019\n",
      "Epoch 24/600\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 0.6934 - accuracy: 0.5061\n",
      "Epoch 25/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6952 - accuracy: 0.5146\n",
      "Epoch 26/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6941 - accuracy: 0.5056\n",
      "Epoch 27/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6939 - accuracy: 0.5027\n",
      "Epoch 28/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6937 - accuracy: 0.5036\n",
      "Epoch 29/600\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 0.6950 - accuracy: 0.4861\n",
      "Epoch 30/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6948 - accuracy: 0.4964\n",
      "Epoch 31/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6943 - accuracy: 0.5039\n",
      "Epoch 32/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6936 - accuracy: 0.5106\n",
      "Epoch 33/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6948 - accuracy: 0.4964\n",
      "Epoch 34/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6951 - accuracy: 0.4931\n",
      "Epoch 35/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6939 - accuracy: 0.4971\n",
      "Epoch 36/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6948 - accuracy: 0.4951\n",
      "Epoch 37/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6943 - accuracy: 0.5014\n",
      "Epoch 38/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6938 - accuracy: 0.5054\n",
      "Epoch 39/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6915 - accuracy: 0.5139\n",
      "Epoch 40/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.5121\n",
      "Epoch 41/600\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 0.6928 - accuracy: 0.5123\n",
      "Epoch 42/600\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 0.6927 - accuracy: 0.5124\n",
      "Epoch 43/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6931 - accuracy: 0.5081\n",
      "Epoch 44/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6929 - accuracy: 0.5111\n",
      "Epoch 45/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6931 - accuracy: 0.5143\n",
      "Epoch 46/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6927 - accuracy: 0.5094\n",
      "Epoch 47/600\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 0.6924 - accuracy: 0.5153\n",
      "Epoch 48/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6929 - accuracy: 0.5109\n",
      "Epoch 49/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6918 - accuracy: 0.5179\n",
      "Epoch 50/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6942 - accuracy: 0.5113\n",
      "Epoch 51/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6929 - accuracy: 0.5114\n",
      "Epoch 52/600\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 0.6922 - accuracy: 0.5149\n",
      "Epoch 53/600\n",
      "110/110 [==============================] - 4s 37ms/step - loss: 0.6923 - accuracy: 0.5169\n",
      "Epoch 54/600\n",
      "110/110 [==============================] - 4s 34ms/step - loss: 0.6920 - accuracy: 0.5176\n",
      "Epoch 55/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6929 - accuracy: 0.5136\n",
      "Epoch 56/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6927 - accuracy: 0.5104\n",
      "Epoch 57/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6922 - accuracy: 0.5169\n",
      "Epoch 58/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6931 - accuracy: 0.5111\n",
      "Epoch 59/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6923 - accuracy: 0.5191\n",
      "Epoch 60/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6919 - accuracy: 0.5164\n",
      "Epoch 61/600\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 0.6932 - accuracy: 0.5114\n",
      "Epoch 62/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6928 - accuracy: 0.5111\n",
      "Epoch 63/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6929 - accuracy: 0.5159\n",
      "Epoch 64/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6920 - accuracy: 0.5210\n",
      "Epoch 65/600\n",
      "110/110 [==============================] - 4s 34ms/step - loss: 0.6923 - accuracy: 0.5164\n",
      "Epoch 66/600\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 0.6924 - accuracy: 0.5136\n",
      "Epoch 67/600\n",
      "110/110 [==============================] - 4s 34ms/step - loss: 0.6925 - accuracy: 0.5090\n",
      "Epoch 68/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6926 - accuracy: 0.5101\n",
      "Epoch 69/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6927 - accuracy: 0.5101\n",
      "Epoch 70/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6921 - accuracy: 0.5144\n",
      "Epoch 71/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6919 - accuracy: 0.5136\n",
      "Epoch 72/600\n",
      "110/110 [==============================] - 4s 34ms/step - loss: 0.6919 - accuracy: 0.5186\n",
      "Epoch 73/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6923 - accuracy: 0.5157\n",
      "Epoch 74/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6925 - accuracy: 0.5040\n",
      "Epoch 75/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6921 - accuracy: 0.5143\n",
      "Epoch 76/600\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.6920 - accuracy: 0.5106\n",
      "Epoch 77/600\n",
      "110/110 [==============================] - 4s 39ms/step - loss: 0.6917 - accuracy: 0.5171\n",
      "Epoch 78/600\n",
      "110/110 [==============================] - 5s 44ms/step - loss: 0.6917 - accuracy: 0.5163\n",
      "Epoch 79/600\n",
      "110/110 [==============================] - 5s 45ms/step - loss: 0.6917 - accuracy: 0.5167\n",
      "Epoch 80/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 4s 32ms/step - loss: 0.6918 - accuracy: 0.5143\n",
      "Epoch 81/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6918 - accuracy: 0.5184\n",
      "Epoch 82/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6909 - accuracy: 0.5234\n",
      "Epoch 83/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6924 - accuracy: 0.5130\n",
      "Epoch 84/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6912 - accuracy: 0.5141\n",
      "Epoch 85/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6918 - accuracy: 0.5166\n",
      "Epoch 86/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6916 - accuracy: 0.5106\n",
      "Epoch 87/600\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 0.6915 - accuracy: 0.5137\n",
      "Epoch 88/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6922 - accuracy: 0.5150\n",
      "Epoch 89/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6918 - accuracy: 0.5123\n",
      "Epoch 90/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6910 - accuracy: 0.5126\n",
      "Epoch 91/600\n",
      "110/110 [==============================] - 3s 26ms/step - loss: 0.6916 - accuracy: 0.5157\n",
      "Epoch 92/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6910 - accuracy: 0.5121\n",
      "Epoch 93/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6909 - accuracy: 0.5151\n",
      "Epoch 94/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6918 - accuracy: 0.4999\n",
      "Epoch 95/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6917 - accuracy: 0.5186\n",
      "Epoch 96/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6911 - accuracy: 0.5180\n",
      "Epoch 97/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6899 - accuracy: 0.5147\n",
      "Epoch 98/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6896 - accuracy: 0.5166\n",
      "Epoch 99/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6913 - accuracy: 0.5140\n",
      "Epoch 100/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6907 - accuracy: 0.5017\n",
      "Epoch 101/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6921 - accuracy: 0.5060\n",
      "Epoch 102/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6892 - accuracy: 0.5179\n",
      "Epoch 103/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6900 - accuracy: 0.5137\n",
      "Epoch 104/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6898 - accuracy: 0.5191\n",
      "Epoch 105/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6911 - accuracy: 0.5206\n",
      "Epoch 106/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6914 - accuracy: 0.5181\n",
      "Epoch 107/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6903 - accuracy: 0.5191\n",
      "Epoch 108/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6907 - accuracy: 0.5231\n",
      "Epoch 109/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6913 - accuracy: 0.5164\n",
      "Epoch 110/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6915 - accuracy: 0.5206\n",
      "Epoch 111/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6918 - accuracy: 0.5146\n",
      "Epoch 112/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6903 - accuracy: 0.5234\n",
      "Epoch 113/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6905 - accuracy: 0.5187\n",
      "Epoch 114/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6903 - accuracy: 0.5131\n",
      "Epoch 115/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6910 - accuracy: 0.5186\n",
      "Epoch 116/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6904 - accuracy: 0.5189\n",
      "Epoch 117/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6918 - accuracy: 0.5161\n",
      "Epoch 118/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6904 - accuracy: 0.5104\n",
      "Epoch 119/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6900 - accuracy: 0.5171\n",
      "Epoch 120/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6900 - accuracy: 0.5156\n",
      "Epoch 121/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6881 - accuracy: 0.5201\n",
      "Epoch 122/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6901 - accuracy: 0.5117\n",
      "Epoch 123/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6909 - accuracy: 0.5193\n",
      "Epoch 124/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6905 - accuracy: 0.5143\n",
      "Epoch 125/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6903 - accuracy: 0.5150\n",
      "Epoch 126/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6863 - accuracy: 0.5227\n",
      "Epoch 127/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6879 - accuracy: 0.5223\n",
      "Epoch 128/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6878 - accuracy: 0.5224\n",
      "Epoch 129/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6871 - accuracy: 0.5300\n",
      "Epoch 130/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6874 - accuracy: 0.5160\n",
      "Epoch 131/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6870 - accuracy: 0.5089\n",
      "Epoch 132/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6870 - accuracy: 0.5211\n",
      "Epoch 133/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6869 - accuracy: 0.5166\n",
      "Epoch 134/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6869 - accuracy: 0.5214\n",
      "Epoch 135/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6863 - accuracy: 0.5301\n",
      "Epoch 136/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6871 - accuracy: 0.5306\n",
      "Epoch 137/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6856 - accuracy: 0.5217\n",
      "Epoch 138/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6846 - accuracy: 0.5214\n",
      "Epoch 139/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6866 - accuracy: 0.5284\n",
      "Epoch 140/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6859 - accuracy: 0.5361\n",
      "Epoch 141/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6819 - accuracy: 0.5410\n",
      "Epoch 142/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6843 - accuracy: 0.5323\n",
      "Epoch 143/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6867 - accuracy: 0.5309\n",
      "Epoch 144/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6835 - accuracy: 0.5341\n",
      "Epoch 145/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6808 - accuracy: 0.5391\n",
      "Epoch 146/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6820 - accuracy: 0.5387\n",
      "Epoch 147/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6824 - accuracy: 0.5433\n",
      "Epoch 148/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6821 - accuracy: 0.5436\n",
      "Epoch 149/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6806 - accuracy: 0.5483\n",
      "Epoch 150/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6810 - accuracy: 0.5489\n",
      "Epoch 151/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6796 - accuracy: 0.5474\n",
      "Epoch 152/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6794 - accuracy: 0.5516\n",
      "Epoch 153/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6771 - accuracy: 0.5460\n",
      "Epoch 154/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6818 - accuracy: 0.5506\n",
      "Epoch 155/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6764 - accuracy: 0.5529\n",
      "Epoch 156/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6748 - accuracy: 0.5524\n",
      "Epoch 157/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6718 - accuracy: 0.5544\n",
      "Epoch 158/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6720 - accuracy: 0.5559\n",
      "Epoch 159/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6673 - accuracy: 0.5610\n",
      "Epoch 160/600\n",
      "110/110 [==============================] - 3s 32ms/step - loss: 0.6743 - accuracy: 0.5560\n",
      "Epoch 161/600\n",
      "110/110 [==============================] - 4s 39ms/step - loss: 0.6681 - accuracy: 0.5510\n",
      "Epoch 162/600\n",
      "110/110 [==============================] - 4s 34ms/step - loss: 0.6685 - accuracy: 0.5571\n",
      "Epoch 163/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6686 - accuracy: 0.5571\n",
      "Epoch 164/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6661 - accuracy: 0.5540\n",
      "Epoch 165/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6655 - accuracy: 0.5603\n",
      "Epoch 166/600\n",
      "110/110 [==============================] - 3s 26ms/step - loss: 0.6672 - accuracy: 0.5534\n",
      "Epoch 167/600\n",
      "110/110 [==============================] - 3s 26ms/step - loss: 0.6691 - accuracy: 0.5573\n",
      "Epoch 168/600\n",
      "110/110 [==============================] - 3s 26ms/step - loss: 0.6645 - accuracy: 0.5671\n",
      "Epoch 169/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6683 - accuracy: 0.5566\n",
      "Epoch 170/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6636 - accuracy: 0.5596\n",
      "Epoch 171/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6669 - accuracy: 0.5609\n",
      "Epoch 172/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6657 - accuracy: 0.5610\n",
      "Epoch 173/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6632 - accuracy: 0.5604\n",
      "Epoch 174/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6625 - accuracy: 0.5614\n",
      "Epoch 175/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6647 - accuracy: 0.5527\n",
      "Epoch 176/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6651 - accuracy: 0.5599\n",
      "Epoch 177/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6628 - accuracy: 0.5573\n",
      "Epoch 178/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6647 - accuracy: 0.5577\n",
      "Epoch 179/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6604 - accuracy: 0.5556\n",
      "Epoch 180/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6592 - accuracy: 0.5606\n",
      "Epoch 181/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6623 - accuracy: 0.5683\n",
      "Epoch 182/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6615 - accuracy: 0.5671\n",
      "Epoch 183/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6612 - accuracy: 0.5741\n",
      "Epoch 184/600\n",
      "110/110 [==============================] - 4s 36ms/step - loss: 0.6584 - accuracy: 0.5723\n",
      "Epoch 185/600\n",
      "110/110 [==============================] - 4s 40ms/step - loss: 0.6581 - accuracy: 0.5704\n",
      "Epoch 186/600\n",
      "110/110 [==============================] - 4s 34ms/step - loss: 0.6575 - accuracy: 0.5736\n",
      "Epoch 187/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6586 - accuracy: 0.5627\n",
      "Epoch 188/600\n",
      "110/110 [==============================] - 4s 32ms/step - loss: 0.6542 - accuracy: 0.5770\n",
      "Epoch 189/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6549 - accuracy: 0.5754\n",
      "Epoch 190/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6561 - accuracy: 0.5757\n",
      "Epoch 191/600\n",
      "110/110 [==============================] - 4s 33ms/step - loss: 0.6557 - accuracy: 0.5754\n",
      "Epoch 192/600\n",
      "110/110 [==============================] - 3s 32ms/step - loss: 0.6551 - accuracy: 0.5804\n",
      "Epoch 193/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6530 - accuracy: 0.5843\n",
      "Epoch 194/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6514 - accuracy: 0.5826\n",
      "Epoch 195/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6492 - accuracy: 0.5849\n",
      "Epoch 196/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6508 - accuracy: 0.5844\n",
      "Epoch 197/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6443 - accuracy: 0.5910\n",
      "Epoch 198/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6539 - accuracy: 0.5797\n",
      "Epoch 199/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6441 - accuracy: 0.5907\n",
      "Epoch 200/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6501 - accuracy: 0.5863\n",
      "Epoch 201/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6469 - accuracy: 0.5954\n",
      "Epoch 202/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6458 - accuracy: 0.5907\n",
      "Epoch 203/600\n",
      "110/110 [==============================] - 3s 27ms/step - loss: 0.6443 - accuracy: 0.5839\n",
      "Epoch 204/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6426 - accuracy: 0.5957\n",
      "Epoch 205/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6449 - accuracy: 0.5884\n",
      "Epoch 206/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6436 - accuracy: 0.5890\n",
      "Epoch 207/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6391 - accuracy: 0.5947\n",
      "Epoch 208/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6429 - accuracy: 0.5953\n",
      "Epoch 209/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6421 - accuracy: 0.5867\n",
      "Epoch 210/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6368 - accuracy: 0.6034\n",
      "Epoch 211/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6379 - accuracy: 0.5983\n",
      "Epoch 212/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6445 - accuracy: 0.5859\n",
      "Epoch 213/600\n",
      "110/110 [==============================] - 3s 31ms/step - loss: 0.6370 - accuracy: 0.5970\n",
      "Epoch 214/600\n",
      "110/110 [==============================] - 3s 32ms/step - loss: 0.6391 - accuracy: 0.5977\n",
      "Epoch 215/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6392 - accuracy: 0.5927\n",
      "Epoch 216/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6403 - accuracy: 0.5986\n",
      "Epoch 217/600\n",
      "110/110 [==============================] - 3s 32ms/step - loss: 0.6440 - accuracy: 0.5843\n",
      "Epoch 218/600\n",
      "110/110 [==============================] - 5s 43ms/step - loss: 0.6421 - accuracy: 0.5881\n",
      "Epoch 219/600\n",
      "110/110 [==============================] - 4s 39ms/step - loss: 0.6438 - accuracy: 0.5901\n",
      "Epoch 220/600\n",
      "110/110 [==============================] - 3s 30ms/step - loss: 0.6395 - accuracy: 0.5896\n",
      "Epoch 221/600\n",
      "110/110 [==============================] - 4s 35ms/step - loss: 0.6362 - accuracy: 0.5989\n",
      "Epoch 222/600\n",
      "110/110 [==============================] - 4s 37ms/step - loss: 0.6366 - accuracy: 0.6014\n",
      "Epoch 223/600\n",
      "110/110 [==============================] - 3s 32ms/step - loss: 0.6335 - accuracy: 0.5934\n",
      "Epoch 224/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6341 - accuracy: 0.5907\n",
      "Epoch 225/600\n",
      "110/110 [==============================] - 3s 28ms/step - loss: 0.6382 - accuracy: 0.5946\n",
      "Epoch 226/600\n",
      "110/110 [==============================] - 3s 29ms/step - loss: 0.6388 - accuracy: 0.5959\n",
      "Epoch 227/600\n",
      "110/110 [==============================] - 4s 39ms/step - loss: 0.6352 - accuracy: 0.6017\n",
      "Epoch 228/600\n",
      "110/110 [==============================] - 4s 37ms/step - loss: 0.6328 - accuracy: 0.5949\n",
      "Epoch 229/600\n",
      "110/110 [==============================] - 5s 47ms/step - loss: 0.6410 - accuracy: 0.5873\n",
      "Epoch 230/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.6385 - accuracy: 0.5930\n",
      "Epoch 231/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.6376 - accuracy: 0.5917\n",
      "Epoch 232/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.6386 - accuracy: 0.5957\n",
      "Epoch 233/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.6329 - accuracy: 0.6007\n",
      "Epoch 234/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6376 - accuracy: 0.5907\n",
      "Epoch 235/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6334 - accuracy: 0.6016\n",
      "Epoch 236/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.6344 - accuracy: 0.6070\n",
      "Epoch 237/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6372 - accuracy: 0.5901\n",
      "Epoch 238/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.6349 - accuracy: 0.6009\n",
      "Epoch 239/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.6318 - accuracy: 0.5943\n",
      "Epoch 240/600\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.6353 - accuracy: 0.6026\n",
      "Epoch 241/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.6330 - accuracy: 0.6026\n",
      "Epoch 242/600\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.6317 - accuracy: 0.6056\n",
      "Epoch 243/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6327 - accuracy: 0.6010\n",
      "Epoch 244/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.6339 - accuracy: 0.5964\n",
      "Epoch 245/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.6397 - accuracy: 0.5957\n",
      "Epoch 246/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.6477 - accuracy: 0.5876\n",
      "Epoch 247/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.6340 - accuracy: 0.5906\n",
      "Epoch 248/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.6314 - accuracy: 0.6027\n",
      "Epoch 249/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.6361 - accuracy: 0.6021\n",
      "Epoch 250/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.6267 - accuracy: 0.6100\n",
      "Epoch 251/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.6369 - accuracy: 0.6004\n",
      "Epoch 252/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.6320 - accuracy: 0.6006\n",
      "Epoch 253/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.6375 - accuracy: 0.5964\n",
      "Epoch 254/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6265 - accuracy: 0.6080\n",
      "Epoch 255/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.6258 - accuracy: 0.6067\n",
      "Epoch 256/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.6236 - accuracy: 0.6014\n",
      "Epoch 257/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.6293 - accuracy: 0.6090\n",
      "Epoch 258/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.6353 - accuracy: 0.5997\n",
      "Epoch 259/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.6290 - accuracy: 0.6151\n",
      "Epoch 260/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.6338 - accuracy: 0.6030\n",
      "Epoch 261/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.6381 - accuracy: 0.5986\n",
      "Epoch 262/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6317 - accuracy: 0.6103\n",
      "Epoch 263/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.6269 - accuracy: 0.6096\n",
      "Epoch 264/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.6242 - accuracy: 0.6163\n",
      "Epoch 265/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.6290 - accuracy: 0.6101\n",
      "Epoch 266/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6264 - accuracy: 0.6016\n",
      "Epoch 267/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.6371 - accuracy: 0.5984\n",
      "Epoch 268/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.6360 - accuracy: 0.6060\n",
      "Epoch 269/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.6262 - accuracy: 0.6100\n",
      "Epoch 270/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.6238 - accuracy: 0.6127\n",
      "Epoch 271/600\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 0.6209 - accuracy: 0.6084\n",
      "Epoch 272/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.6302 - accuracy: 0.6020\n",
      "Epoch 273/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.6230 - accuracy: 0.6160\n",
      "Epoch 274/600\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.6234 - accuracy: 0.6109\n",
      "Epoch 275/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6317 - accuracy: 0.5979\n",
      "Epoch 276/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.6256 - accuracy: 0.6059\n",
      "Epoch 277/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6227 - accuracy: 0.6121\n",
      "Epoch 278/600\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.6199 - accuracy: 0.6203\n",
      "Epoch 279/600\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.6206 - accuracy: 0.6090\n",
      "Epoch 280/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.6260 - accuracy: 0.6127\n",
      "Epoch 281/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.6189 - accuracy: 0.6143\n",
      "Epoch 282/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.6305 - accuracy: 0.6016\n",
      "Epoch 283/600\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.6193 - accuracy: 0.6107\n",
      "Epoch 284/600\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.6277 - accuracy: 0.6006\n",
      "Epoch 285/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.6276 - accuracy: 0.6074\n",
      "Epoch 286/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.6163 - accuracy: 0.6126\n",
      "Epoch 287/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.6099 - accuracy: 0.6194\n",
      "Epoch 288/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.6254 - accuracy: 0.5977\n",
      "Epoch 289/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.6119 - accuracy: 0.6180\n",
      "Epoch 290/600\n",
      "110/110 [==============================] - 9s 78ms/step - loss: 0.6101 - accuracy: 0.6116\n",
      "Epoch 291/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.6064 - accuracy: 0.6267\n",
      "Epoch 292/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.6118 - accuracy: 0.6190\n",
      "Epoch 293/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.6165 - accuracy: 0.6164\n",
      "Epoch 294/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5967 - accuracy: 0.6260\n",
      "Epoch 295/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5910 - accuracy: 0.6273\n",
      "Epoch 296/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.6060 - accuracy: 0.6270\n",
      "Epoch 297/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.6086 - accuracy: 0.6167\n",
      "Epoch 298/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5994 - accuracy: 0.6244\n",
      "Epoch 299/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5943 - accuracy: 0.6301\n",
      "Epoch 300/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5896 - accuracy: 0.6316\n",
      "Epoch 301/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.6073 - accuracy: 0.6233\n",
      "Epoch 302/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.6024 - accuracy: 0.6374\n",
      "Epoch 303/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.5939 - accuracy: 0.6370\n",
      "Epoch 304/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.6123 - accuracy: 0.6276\n",
      "Epoch 305/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5954 - accuracy: 0.6321\n",
      "Epoch 306/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5888 - accuracy: 0.6409\n",
      "Epoch 307/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.6075 - accuracy: 0.6277\n",
      "Epoch 308/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.6028 - accuracy: 0.6289\n",
      "Epoch 309/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.5901 - accuracy: 0.6370\n",
      "Epoch 310/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5849 - accuracy: 0.6396\n",
      "Epoch 311/600\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.6015 - accuracy: 0.6344\n",
      "Epoch 312/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5953 - accuracy: 0.6370\n",
      "Epoch 313/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5896 - accuracy: 0.6431\n",
      "Epoch 314/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5861 - accuracy: 0.6420\n",
      "Epoch 315/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 66ms/step - loss: 0.5803 - accuracy: 0.6454\n",
      "Epoch 316/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5893 - accuracy: 0.6450\n",
      "Epoch 317/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5833 - accuracy: 0.6471\n",
      "Epoch 318/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5859 - accuracy: 0.6453\n",
      "Epoch 319/600\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.5758 - accuracy: 0.6614\n",
      "Epoch 320/600\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.5838 - accuracy: 0.6476\n",
      "Epoch 321/600\n",
      "110/110 [==============================] - 9s 79ms/step - loss: 0.5884 - accuracy: 0.6474\n",
      "Epoch 322/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.5848 - accuracy: 0.6421\n",
      "Epoch 323/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5960 - accuracy: 0.6444\n",
      "Epoch 324/600\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.5821 - accuracy: 0.6514\n",
      "Epoch 325/600\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.5807 - accuracy: 0.6533\n",
      "Epoch 326/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5757 - accuracy: 0.6513\n",
      "Epoch 327/600\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.5815 - accuracy: 0.6561\n",
      "Epoch 328/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.5721 - accuracy: 0.6621\n",
      "Epoch 329/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5670 - accuracy: 0.6716\n",
      "Epoch 330/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5856 - accuracy: 0.6613\n",
      "Epoch 331/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5692 - accuracy: 0.6659\n",
      "Epoch 332/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5841 - accuracy: 0.6540\n",
      "Epoch 333/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5725 - accuracy: 0.6699\n",
      "Epoch 334/600\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.5732 - accuracy: 0.6689\n",
      "Epoch 335/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.5652 - accuracy: 0.6839\n",
      "Epoch 336/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.5660 - accuracy: 0.6724\n",
      "Epoch 337/600\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.5658 - accuracy: 0.6723\n",
      "Epoch 338/600\n",
      "110/110 [==============================] - 8s 68ms/step - loss: 0.5462 - accuracy: 0.6967\n",
      "Epoch 339/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5460 - accuracy: 0.6970\n",
      "Epoch 340/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5698 - accuracy: 0.6773\n",
      "Epoch 341/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5415 - accuracy: 0.7020\n",
      "Epoch 342/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5624 - accuracy: 0.6901\n",
      "Epoch 343/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5636 - accuracy: 0.6813\n",
      "Epoch 344/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5707 - accuracy: 0.6746\n",
      "Epoch 345/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5599 - accuracy: 0.6821\n",
      "Epoch 346/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5600 - accuracy: 0.6841\n",
      "Epoch 347/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5618 - accuracy: 0.6770\n",
      "Epoch 348/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5478 - accuracy: 0.6950\n",
      "Epoch 349/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5604 - accuracy: 0.6831\n",
      "Epoch 350/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.5396 - accuracy: 0.7050\n",
      "Epoch 351/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.5308 - accuracy: 0.7100\n",
      "Epoch 352/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.5296 - accuracy: 0.7193\n",
      "Epoch 353/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.5672 - accuracy: 0.6840\n",
      "Epoch 354/600\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.5347 - accuracy: 0.7111\n",
      "Epoch 355/600\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 0.5232 - accuracy: 0.7161\n",
      "Epoch 356/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.5260 - accuracy: 0.7200\n",
      "Epoch 357/600\n",
      "110/110 [==============================] - 9s 86ms/step - loss: 0.5317 - accuracy: 0.7097\n",
      "Epoch 358/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.5323 - accuracy: 0.7161\n",
      "Epoch 359/600\n",
      "110/110 [==============================] - 8s 77ms/step - loss: 0.5763 - accuracy: 0.6859\n",
      "Epoch 360/600\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 0.5563 - accuracy: 0.6897\n",
      "Epoch 361/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.5604 - accuracy: 0.6923\n",
      "Epoch 362/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.5398 - accuracy: 0.7060\n",
      "Epoch 363/600\n",
      "110/110 [==============================] - 9s 80ms/step - loss: 0.5221 - accuracy: 0.7234\n",
      "Epoch 364/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.5264 - accuracy: 0.7173\n",
      "Epoch 365/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5186 - accuracy: 0.7201\n",
      "Epoch 366/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5251 - accuracy: 0.7193\n",
      "Epoch 367/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5287 - accuracy: 0.7211\n",
      "Epoch 368/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5332 - accuracy: 0.7081\n",
      "Epoch 369/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5400 - accuracy: 0.7106\n",
      "Epoch 370/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5222 - accuracy: 0.7304\n",
      "Epoch 371/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5445 - accuracy: 0.7127\n",
      "Epoch 372/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5343 - accuracy: 0.7149\n",
      "Epoch 373/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5357 - accuracy: 0.7236\n",
      "Epoch 374/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5411 - accuracy: 0.7180\n",
      "Epoch 375/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5342 - accuracy: 0.7239\n",
      "Epoch 376/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5221 - accuracy: 0.7277\n",
      "Epoch 377/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5394 - accuracy: 0.7153\n",
      "Epoch 378/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5289 - accuracy: 0.7246\n",
      "Epoch 379/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5215 - accuracy: 0.7299\n",
      "Epoch 380/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5368 - accuracy: 0.7147\n",
      "Epoch 381/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5205 - accuracy: 0.7229\n",
      "Epoch 382/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5447 - accuracy: 0.7137\n",
      "Epoch 383/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.5202 - accuracy: 0.7264\n",
      "Epoch 384/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5208 - accuracy: 0.7256\n",
      "Epoch 385/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5237 - accuracy: 0.7271\n",
      "Epoch 386/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5629 - accuracy: 0.6953\n",
      "Epoch 387/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.5278 - accuracy: 0.7180\n",
      "Epoch 388/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5232 - accuracy: 0.7271\n",
      "Epoch 389/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5339 - accuracy: 0.7230\n",
      "Epoch 390/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5223 - accuracy: 0.7267\n",
      "Epoch 391/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5160 - accuracy: 0.7317\n",
      "Epoch 392/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5246 - accuracy: 0.7311\n",
      "Epoch 393/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5148 - accuracy: 0.7387\n",
      "Epoch 394/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.5191 - accuracy: 0.7290\n",
      "Epoch 395/600\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.5162 - accuracy: 0.7306\n",
      "Epoch 396/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.5118 - accuracy: 0.7397\n",
      "Epoch 397/600\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.5215 - accuracy: 0.7289\n",
      "Epoch 398/600\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.5140 - accuracy: 0.7317\n",
      "Epoch 399/600\n",
      "110/110 [==============================] - 6s 51ms/step - loss: 0.5184 - accuracy: 0.7329\n",
      "Epoch 400/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.5321 - accuracy: 0.7204\n",
      "Epoch 401/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.5104 - accuracy: 0.7381\n",
      "Epoch 402/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.5192 - accuracy: 0.7311\n",
      "Epoch 403/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5181 - accuracy: 0.7346\n",
      "Epoch 404/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.5113 - accuracy: 0.7407\n",
      "Epoch 405/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5156 - accuracy: 0.7359\n",
      "Epoch 406/600\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.5161 - accuracy: 0.7311\n",
      "Epoch 407/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5193 - accuracy: 0.7287\n",
      "Epoch 408/600\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.5113 - accuracy: 0.7349\n",
      "Epoch 409/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5176 - accuracy: 0.7289\n",
      "Epoch 410/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5064 - accuracy: 0.7369\n",
      "Epoch 411/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5116 - accuracy: 0.7361\n",
      "Epoch 412/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5085 - accuracy: 0.7320\n",
      "Epoch 413/600\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 0.5172 - accuracy: 0.7304\n",
      "Epoch 414/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.5315 - accuracy: 0.7130\n",
      "Epoch 415/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.5296 - accuracy: 0.7154\n",
      "Epoch 416/600\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.5116 - accuracy: 0.7353\n",
      "Epoch 417/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.5219 - accuracy: 0.7229\n",
      "Epoch 418/600\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.5126 - accuracy: 0.7323\n",
      "Epoch 419/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.5159 - accuracy: 0.7304\n",
      "Epoch 420/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.5055 - accuracy: 0.7380\n",
      "Epoch 421/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.5236 - accuracy: 0.7181\n",
      "Epoch 422/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.5147 - accuracy: 0.7300\n",
      "Epoch 423/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.5016 - accuracy: 0.7370\n",
      "Epoch 424/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.5021 - accuracy: 0.7463\n",
      "Epoch 425/600\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.5063 - accuracy: 0.7429\n",
      "Epoch 426/600\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.5197 - accuracy: 0.7254\n",
      "Epoch 427/600\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.5223 - accuracy: 0.7264\n",
      "Epoch 428/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.5082 - accuracy: 0.7331\n",
      "Epoch 429/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.4979 - accuracy: 0.7429\n",
      "Epoch 430/600\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.4909 - accuracy: 0.7484\n",
      "Epoch 431/600\n",
      "110/110 [==============================] - 8s 77ms/step - loss: 0.5162 - accuracy: 0.7241\n",
      "Epoch 432/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.5211 - accuracy: 0.7267\n",
      "Epoch 433/600\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.5290 - accuracy: 0.7194\n",
      "Epoch 434/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.5267 - accuracy: 0.7293\n",
      "Epoch 435/600\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.5405 - accuracy: 0.7116\n",
      "Epoch 436/600\n",
      "110/110 [==============================] - 8s 68ms/step - loss: 0.5138 - accuracy: 0.7329\n",
      "Epoch 437/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.5176 - accuracy: 0.7334\n",
      "Epoch 438/600\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.5150 - accuracy: 0.7324\n",
      "Epoch 439/600\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.5100 - accuracy: 0.7347\n",
      "Epoch 440/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.5120 - accuracy: 0.7293\n",
      "Epoch 441/600\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 0.4936 - accuracy: 0.7486\n",
      "Epoch 442/600\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.5047 - accuracy: 0.7407\n",
      "Epoch 443/600\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.5184 - accuracy: 0.7244\n",
      "Epoch 444/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.5108 - accuracy: 0.7350\n",
      "Epoch 445/600\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.5094 - accuracy: 0.7316\n",
      "Epoch 446/600\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.5164 - accuracy: 0.7280\n",
      "Epoch 447/600\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.5150 - accuracy: 0.7284\n",
      "Epoch 448/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.5065 - accuracy: 0.7340\n",
      "Epoch 449/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.5123 - accuracy: 0.7330\n",
      "Epoch 450/600\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.5267 - accuracy: 0.7206\n",
      "Epoch 451/600\n",
      "110/110 [==============================] - 8s 77ms/step - loss: 0.5220 - accuracy: 0.7239\n",
      "Epoch 452/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.5725 - accuracy: 0.6963\n",
      "Epoch 453/600\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.5094 - accuracy: 0.7389\n",
      "Epoch 454/600\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.5073 - accuracy: 0.7371\n",
      "Epoch 455/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.5417 - accuracy: 0.7101\n",
      "Epoch 456/600\n",
      "110/110 [==============================] - 9s 79ms/step - loss: 0.5077 - accuracy: 0.7384\n",
      "Epoch 457/600\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 0.5069 - accuracy: 0.7399\n",
      "Epoch 458/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.5094 - accuracy: 0.7370\n",
      "Epoch 459/600\n",
      "110/110 [==============================] - 8s 77ms/step - loss: 0.5088 - accuracy: 0.7380\n",
      "Epoch 460/600\n",
      "110/110 [==============================] - 8s 77ms/step - loss: 0.5152 - accuracy: 0.7337\n",
      "Epoch 461/600\n",
      "110/110 [==============================] - 9s 81ms/step - loss: 0.5189 - accuracy: 0.7316\n",
      "Epoch 462/600\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 0.5137 - accuracy: 0.7367\n",
      "Epoch 463/600\n",
      "110/110 [==============================] - 9s 78ms/step - loss: 0.5164 - accuracy: 0.7356\n",
      "Epoch 464/600\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.4970 - accuracy: 0.7460\n",
      "Epoch 465/600\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.5064 - accuracy: 0.7391\n",
      "Epoch 466/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.5199 - accuracy: 0.7254\n",
      "Epoch 467/600\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.5169 - accuracy: 0.7327\n",
      "Epoch 468/600\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.5287 - accuracy: 0.7193\n",
      "Epoch 469/600\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.5145 - accuracy: 0.7320\n",
      "Epoch 470/600\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.5059 - accuracy: 0.7409\n",
      "Epoch 471/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 7s 68ms/step - loss: 0.5054 - accuracy: 0.7349\n",
      "Epoch 472/600\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.5331 - accuracy: 0.7217\n",
      "Epoch 473/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5068 - accuracy: 0.7349\n",
      "Epoch 474/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.4971 - accuracy: 0.7401\n",
      "Epoch 475/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.5061 - accuracy: 0.7390\n",
      "Epoch 476/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5076 - accuracy: 0.7363\n",
      "Epoch 477/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5092 - accuracy: 0.7346\n",
      "Epoch 478/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5090 - accuracy: 0.7351\n",
      "Epoch 479/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5052 - accuracy: 0.7389\n",
      "Epoch 480/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5173 - accuracy: 0.7309\n",
      "Epoch 481/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5008 - accuracy: 0.7467\n",
      "Epoch 482/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.4904 - accuracy: 0.7494\n",
      "Epoch 483/600\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.5009 - accuracy: 0.7399\n",
      "Epoch 484/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5081 - accuracy: 0.7427\n",
      "Epoch 485/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5014 - accuracy: 0.7449\n",
      "Epoch 486/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.4961 - accuracy: 0.7484\n",
      "Epoch 487/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.4919 - accuracy: 0.7467\n",
      "Epoch 488/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5025 - accuracy: 0.7490\n",
      "Epoch 489/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5008 - accuracy: 0.7427\n",
      "Epoch 490/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5214 - accuracy: 0.7309\n",
      "Epoch 491/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.4949 - accuracy: 0.7450\n",
      "Epoch 492/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.4957 - accuracy: 0.7461\n",
      "Epoch 493/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.4970 - accuracy: 0.7499\n",
      "Epoch 494/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.5028 - accuracy: 0.7487\n",
      "Epoch 495/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.5021 - accuracy: 0.7463\n",
      "Epoch 496/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.4979 - accuracy: 0.7446\n",
      "Epoch 497/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.4987 - accuracy: 0.7477\n",
      "Epoch 498/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.5088 - accuracy: 0.7430\n",
      "Epoch 499/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.4996 - accuracy: 0.7457\n",
      "Epoch 500/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.4840 - accuracy: 0.7606\n",
      "Epoch 501/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.4966 - accuracy: 0.7440\n",
      "Epoch 502/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.4756 - accuracy: 0.7613\n",
      "Epoch 503/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.4910 - accuracy: 0.7496\n",
      "Epoch 504/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.4792 - accuracy: 0.7613\n",
      "Epoch 505/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.4829 - accuracy: 0.7620\n",
      "Epoch 506/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.4883 - accuracy: 0.7496\n",
      "Epoch 507/600\n",
      "110/110 [==============================] - 8s 68ms/step - loss: 0.4778 - accuracy: 0.7529\n",
      "Epoch 508/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.4973 - accuracy: 0.7480\n",
      "Epoch 509/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.4719 - accuracy: 0.7637\n",
      "Epoch 510/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.4996 - accuracy: 0.7470\n",
      "Epoch 511/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.4820 - accuracy: 0.7624\n",
      "Epoch 512/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.4807 - accuracy: 0.7597\n",
      "Epoch 513/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.4871 - accuracy: 0.7569\n",
      "Epoch 514/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5095 - accuracy: 0.7399\n",
      "Epoch 515/600\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.4842 - accuracy: 0.7597\n",
      "Epoch 516/600\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 0.5033 - accuracy: 0.7526\n",
      "Epoch 517/600\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 0.4916 - accuracy: 0.7549\n",
      "Epoch 518/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5042 - accuracy: 0.7436\n",
      "Epoch 519/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.4704 - accuracy: 0.7626\n",
      "Epoch 520/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.4879 - accuracy: 0.7470\n",
      "Epoch 521/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.4787 - accuracy: 0.7593\n",
      "Epoch 522/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.4783 - accuracy: 0.7666\n",
      "Epoch 523/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.4731 - accuracy: 0.7644\n",
      "Epoch 524/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.4892 - accuracy: 0.7600\n",
      "Epoch 525/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.4798 - accuracy: 0.7630\n",
      "Epoch 526/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.4851 - accuracy: 0.7573\n",
      "Epoch 527/600\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.4932 - accuracy: 0.7490\n",
      "Epoch 528/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5236 - accuracy: 0.7359\n",
      "Epoch 529/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5272 - accuracy: 0.7317\n",
      "Epoch 530/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.7194 - accuracy: 0.5220\n",
      "Epoch 531/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6412 - accuracy: 0.5859\n",
      "Epoch 532/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.6307 - accuracy: 0.6039\n",
      "Epoch 533/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.6217 - accuracy: 0.6117\n",
      "Epoch 534/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.6059 - accuracy: 0.6304\n",
      "Epoch 535/600\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.6014 - accuracy: 0.6319\n",
      "Epoch 536/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.6057 - accuracy: 0.6267\n",
      "Epoch 537/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5969 - accuracy: 0.6443\n",
      "Epoch 538/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.6011 - accuracy: 0.6313\n",
      "Epoch 539/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.5973 - accuracy: 0.6391\n",
      "Epoch 540/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.6030 - accuracy: 0.6297\n",
      "Epoch 541/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.6026 - accuracy: 0.6339\n",
      "Epoch 542/600\n",
      "110/110 [==============================] - 7s 61ms/step - loss: 0.5894 - accuracy: 0.6337\n",
      "Epoch 543/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.6079 - accuracy: 0.6281\n",
      "Epoch 544/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5854 - accuracy: 0.6457\n",
      "Epoch 545/600\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 0.5935 - accuracy: 0.6409\n",
      "Epoch 546/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.5882 - accuracy: 0.6443\n",
      "Epoch 547/600\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.5781 - accuracy: 0.6529\n",
      "Epoch 548/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5887 - accuracy: 0.6454\n",
      "Epoch 549/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 6s 56ms/step - loss: 0.5973 - accuracy: 0.6413\n",
      "Epoch 550/600\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.5954 - accuracy: 0.6370\n",
      "Epoch 551/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5840 - accuracy: 0.6561\n",
      "Epoch 552/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5599 - accuracy: 0.6774\n",
      "Epoch 553/600\n",
      "110/110 [==============================] - 6s 55ms/step - loss: 0.5728 - accuracy: 0.6633\n",
      "Epoch 554/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5618 - accuracy: 0.6764\n",
      "Epoch 555/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5510 - accuracy: 0.6893\n",
      "Epoch 556/600\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.5454 - accuracy: 0.7011\n",
      "Epoch 557/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5376 - accuracy: 0.7041\n",
      "Epoch 558/600\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 0.5306 - accuracy: 0.7087\n",
      "Epoch 559/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5190 - accuracy: 0.7223\n",
      "Epoch 560/600\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 0.5134 - accuracy: 0.7260\n",
      "Epoch 561/600\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 0.5274 - accuracy: 0.7167\n",
      "Epoch 562/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.5374 - accuracy: 0.7040\n",
      "Epoch 563/600\n",
      "110/110 [==============================] - 6s 53ms/step - loss: 0.5255 - accuracy: 0.7146\n",
      "Epoch 564/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5169 - accuracy: 0.7296\n",
      "Epoch 565/600\n",
      "110/110 [==============================] - 6s 54ms/step - loss: 0.5207 - accuracy: 0.7221\n",
      "Epoch 566/600\n",
      "110/110 [==============================] - 6s 56ms/step - loss: 0.5236 - accuracy: 0.7214\n",
      "Epoch 567/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5223 - accuracy: 0.7221\n",
      "Epoch 568/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5107 - accuracy: 0.7320\n",
      "Epoch 569/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.5213 - accuracy: 0.7160\n",
      "Epoch 570/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5098 - accuracy: 0.7293\n",
      "Epoch 571/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.4977 - accuracy: 0.7379\n",
      "Epoch 572/600\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.4954 - accuracy: 0.7363\n",
      "Epoch 573/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.4942 - accuracy: 0.7420\n",
      "Epoch 574/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.5019 - accuracy: 0.7346\n",
      "Epoch 575/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5128 - accuracy: 0.7239\n",
      "Epoch 576/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5037 - accuracy: 0.7299\n",
      "Epoch 577/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5179 - accuracy: 0.7164\n",
      "Epoch 578/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.5133 - accuracy: 0.7247\n",
      "Epoch 579/600\n",
      "110/110 [==============================] - 6s 59ms/step - loss: 0.5039 - accuracy: 0.7367\n",
      "Epoch 580/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4864 - accuracy: 0.7506\n",
      "Epoch 581/600\n",
      "110/110 [==============================] - 16s 147ms/step - loss: 0.4918 - accuracy: 0.7456\n",
      "Epoch 582/600\n",
      "110/110 [==============================] - 9s 86ms/step - loss: 0.4812 - accuracy: 0.7563\n",
      "Epoch 583/600\n",
      "110/110 [==============================] - 6s 58ms/step - loss: 0.5132 - accuracy: 0.7330\n",
      "Epoch 584/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.5060 - accuracy: 0.7346\n",
      "Epoch 585/600\n",
      "110/110 [==============================] - 15s 140ms/step - loss: 0.5072 - accuracy: 0.7266\n",
      "Epoch 586/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.5244 - accuracy: 0.7173\n",
      "Epoch 587/600\n",
      "110/110 [==============================] - 9s 81ms/step - loss: 0.5033 - accuracy: 0.7379\n",
      "Epoch 588/600\n",
      "110/110 [==============================] - 6s 57ms/step - loss: 0.4923 - accuracy: 0.7436\n",
      "Epoch 589/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.4812 - accuracy: 0.7579\n",
      "Epoch 590/600\n",
      "110/110 [==============================] - 7s 63ms/step - loss: 0.5139 - accuracy: 0.7237\n",
      "Epoch 591/600\n",
      "110/110 [==============================] - 41s 372ms/step - loss: 0.4590 - accuracy: 0.7747\n",
      "Epoch 592/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.4935 - accuracy: 0.7523\n",
      "Epoch 593/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.4777 - accuracy: 0.7671\n",
      "Epoch 594/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.4672 - accuracy: 0.7700\n",
      "Epoch 595/600\n",
      "110/110 [==============================] - 13s 122ms/step - loss: 0.4760 - accuracy: 0.7603\n",
      "Epoch 596/600\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 0.4979 - accuracy: 0.7486\n",
      "Epoch 597/600\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.4772 - accuracy: 0.7637\n",
      "Epoch 598/600\n",
      "110/110 [==============================] - 7s 60ms/step - loss: 0.4898 - accuracy: 0.7564\n",
      "Epoch 599/600\n",
      "110/110 [==============================] - 32s 294ms/step - loss: 0.4702 - accuracy: 0.7716\n",
      "Epoch 600/600\n",
      "110/110 [==============================] - 20s 179ms/step - loss: 0.4841 - accuracy: 0.7591\n",
      "94/94 [==============================] - 10s 69ms/step - loss: 1.1291 - accuracy: 0.5500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1290781497955322, 0.550000011920929]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmodel.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "qmodel.fit(x_train_coded, y_train, batch_size=64, epochs=600)\n",
    "qmodel.evaluate(x_test_coded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2cb293",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
