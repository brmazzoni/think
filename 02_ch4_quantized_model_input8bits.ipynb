{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb10a1f",
   "metadata": {},
   "source": [
    "# Challenge 4 study - Quantized Model with First Layer on pre-processor (SW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543e567",
   "metadata": {},
   "source": [
    "## Import libraries and data, init virtual device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c11ff1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 22:54:48.324360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-10 22:54:48.804944: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-10 22:54:48.804984: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-10 22:54:48.874556: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-10 22:54:52.519459: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-10 22:54:52.519759: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-10 22:54:52.519789: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-10 22:54:57.742507: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-10 22:54:57.742588: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-10 22:54:57.742632: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (87c26121fd32): /proc/driver/nvidia/version does not exist\n",
      "2022-11-10 22:54:57.743091: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, ReLU\n",
    "\n",
    "from akida import Device, AKD1000\n",
    "import cnn2snn\n",
    "\n",
    "device = AKD1000()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f448ce",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53acf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>224</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>242</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>138</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>81</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>95</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>60</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x    y  color\n",
       "0     219  139      1\n",
       "1     170   68      0\n",
       "2     113  147      0\n",
       "3     202  249      0\n",
       "4     224   54      1\n",
       "...   ...  ...    ...\n",
       "9995  242  192      0\n",
       "9996  138   16      1\n",
       "9997   81  114      1\n",
       "9998   95  238      1\n",
       "9999   60   78      0\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_ch4 = np.load('coords_ch4.npy')\n",
    "color = np.load('result_ch4.npy')\n",
    "\n",
    "# Pack in a dataframe and scale for 8-bits quantization (first layer will be quantized on 8-bits)\n",
    "data = pd.DataFrame(coords_ch4, columns = ['x', 'y'])\n",
    "data = round(255*data).astype(np.uint8)\n",
    "\n",
    "# Shuffle and split train/test\n",
    "data['color'] = color\n",
    "data_train = data.sample(frac=0.7, axis=0)\n",
    "data_test = data.drop(data_train.index)\n",
    "\n",
    "# Split x y\n",
    "x_train = data_train.drop('color', axis=1)\n",
    "y_train = data_train['color']\n",
    "x_test = data_test.drop('color', axis=1)\n",
    "y_test = data_test['color']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc350f17",
   "metadata": {},
   "source": [
    "## Model creation with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e95b418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Sequential(name=\"Base_ch4\")\n",
    "base.add(Dense(1000, input_shape=(2,), name='FC1'))\n",
    "base.add(ReLU(name='relu1'))\n",
    "base.add(Dense(500, input_shape=(2,), name='FC2'))\n",
    "base.add(ReLU(name='relu2'))\n",
    "base.add(Dense(250, input_shape=(2,), name='FC3'))\n",
    "base.add(ReLU(name='relu3'))\n",
    "base.add(Dense(100, input_shape=(2,), name='FC4'))\n",
    "base.add(ReLU(name='relu4'))\n",
    "base.add(Dense(50, input_shape=(2,), name='FC5'))\n",
    "base.add(ReLU(name='relu5'))\n",
    "base.add(Dense(1, input_shape=(2,), name='FC6'))\n",
    "base.add(Activation('sigmoid', name='sigmoid'))\n",
    "\n",
    "#base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43e0b4",
   "metadata": {},
   "source": [
    "## Model quantization (4-bits, input: 8-bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1390dddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " FC1 (QuantizedDense)        (None, 1000)              3000      \n",
      "                                                                 \n",
      " relu1 (QuantizedReLU)       (None, 1000)              0         \n",
      "                                                                 \n",
      " FC2 (QuantizedDense)        (None, 500)               500500    \n",
      "                                                                 \n",
      " relu2 (QuantizedReLU)       (None, 500)               0         \n",
      "                                                                 \n",
      " FC3 (QuantizedDense)        (None, 250)               125250    \n",
      "                                                                 \n",
      " relu3 (QuantizedReLU)       (None, 250)               0         \n",
      "                                                                 \n",
      " FC4 (QuantizedDense)        (None, 100)               25100     \n",
      "                                                                 \n",
      " relu4 (QuantizedReLU)       (None, 100)               0         \n",
      "                                                                 \n",
      " FC5 (QuantizedDense)        (None, 50)                5050      \n",
      "                                                                 \n",
      " relu5 (QuantizedReLU)       (None, 50)                0         \n",
      "                                                                 \n",
      " FC6 (QuantizedDense)        (None, 1)                 51        \n",
      "                                                                 \n",
      " sigmoid (Activation)        (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 658,951\n",
      "Trainable params: 658,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Akida Compatibility: True\n"
     ]
    }
   ],
   "source": [
    "qmodel = cnn2snn.quantize(base, weight_quantization=4, activ_quantization=4, input_weight_quantization=8)\n",
    "qmodel.summary()\n",
    "\n",
    "print('\\nAkida Compatibility:', cnn2snn.check_model_compatibility(qmodel, input_is_image=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad8c8a",
   "metadata": {},
   "source": [
    "## Preview akida model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2c5bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model Summary                   \n",
      "___________________________________________________\n",
      "Input shape  Output shape  Sequences  Layers  NPs\n",
      "===================================================\n",
      "[1, 1, 2]    [1, 1, 1]     2          7       5  \n",
      "___________________________________________________\n",
      "\n",
      "____________________________________________________\n",
      "Layer (type)  Output shape  Kernel shape       NPs\n",
      "\n",
      "================= SW/FC1 (Software) ================\n",
      "\n",
      "FC1 (Fully.)  [1, 1, 1000]  (1, 1, 2, 1000)    N/A\n",
      "\n",
      "==== HW/FC2-FC6 (Hardware) - size: 520116 bytes ====\n",
      "\n",
      "FC2 (Fully.)  [1, 1, 500]   (1, 1, 1000, 500)  1  \n",
      "____________________________________________________\n",
      "FC3 (Fully.)  [1, 1, 250]   (1, 1, 500, 250)   1  \n",
      "____________________________________________________\n",
      "FC4 (Fully.)  [1, 1, 100]   (1, 1, 250, 100)   1  \n",
      "____________________________________________________\n",
      "FC5 (Fully.)  [1, 1, 50]    (1, 1, 100, 50)    1  \n",
      "____________________________________________________\n",
      "FC6 (Fully.)  [1, 1, 1]     (1, 1, 50, 1)      1  \n",
      "____________________________________________________\n"
     ]
    }
   ],
   "source": [
    "akmodel = cnn2snn.convert(qmodel, input_is_image=False)\n",
    "akmodel.map(device)\n",
    "akmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957d01f",
   "metadata": {},
   "source": [
    "## Train quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c9e56b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "110/110 [==============================] - 23s 106ms/step - loss: 0.7752 - accuracy: 0.5214\n",
      "Epoch 2/600\n",
      "110/110 [==============================] - 9s 82ms/step - loss: 0.6735 - accuracy: 0.5631\n",
      "Epoch 3/600\n",
      "110/110 [==============================] - 9s 86ms/step - loss: 0.6856 - accuracy: 0.5556\n",
      "Epoch 4/600\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.6625 - accuracy: 0.5706\n",
      "Epoch 5/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.6258 - accuracy: 0.5890\n",
      "Epoch 6/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.6178 - accuracy: 0.6036\n",
      "Epoch 7/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.5966 - accuracy: 0.6283\n",
      "Epoch 8/600\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.6010 - accuracy: 0.6176\n",
      "Epoch 9/600\n",
      "110/110 [==============================] - 11s 95ms/step - loss: 0.5956 - accuracy: 0.6293\n",
      "Epoch 10/600\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.5734 - accuracy: 0.6391\n",
      "Epoch 11/600\n",
      "110/110 [==============================] - 9s 78ms/step - loss: 0.5614 - accuracy: 0.6499\n",
      "Epoch 12/600\n",
      "110/110 [==============================] - 9s 81ms/step - loss: 0.5626 - accuracy: 0.6530\n",
      "Epoch 13/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.5444 - accuracy: 0.6604\n",
      "Epoch 14/600\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.5717 - accuracy: 0.6447\n",
      "Epoch 15/600\n",
      "110/110 [==============================] - 10s 89ms/step - loss: 0.5308 - accuracy: 0.6769\n",
      "Epoch 16/600\n",
      "110/110 [==============================] - 10s 89ms/step - loss: 0.5386 - accuracy: 0.6601\n",
      "Epoch 17/600\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.5227 - accuracy: 0.6870\n",
      "Epoch 18/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.5186 - accuracy: 0.6814\n",
      "Epoch 19/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.4949 - accuracy: 0.6999\n",
      "Epoch 20/600\n",
      "110/110 [==============================] - 9s 85ms/step - loss: 0.4977 - accuracy: 0.6944\n",
      "Epoch 21/600\n",
      "110/110 [==============================] - 9s 87ms/step - loss: 0.4783 - accuracy: 0.7140\n",
      "Epoch 22/600\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.4807 - accuracy: 0.7200\n",
      "Epoch 23/600\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.4799 - accuracy: 0.7210\n",
      "Epoch 24/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.4642 - accuracy: 0.7233\n",
      "Epoch 25/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.4637 - accuracy: 0.7311\n",
      "Epoch 26/600\n",
      "110/110 [==============================] - 9s 85ms/step - loss: 0.4416 - accuracy: 0.7440\n",
      "Epoch 27/600\n",
      "110/110 [==============================] - 9s 81ms/step - loss: 0.4463 - accuracy: 0.7367\n",
      "Epoch 28/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.4525 - accuracy: 0.7339\n",
      "Epoch 29/600\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.4385 - accuracy: 0.7420\n",
      "Epoch 30/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.4431 - accuracy: 0.7447\n",
      "Epoch 31/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.4303 - accuracy: 0.7431\n",
      "Epoch 32/600\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.4295 - accuracy: 0.7620\n",
      "Epoch 33/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.4314 - accuracy: 0.7566\n",
      "Epoch 34/600\n",
      "110/110 [==============================] - 10s 89ms/step - loss: 0.4125 - accuracy: 0.7640\n",
      "Epoch 35/600\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 0.4061 - accuracy: 0.7659\n",
      "Epoch 36/600\n",
      "110/110 [==============================] - 13s 118ms/step - loss: 0.4082 - accuracy: 0.7581\n",
      "Epoch 37/600\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 0.3993 - accuracy: 0.7736\n",
      "Epoch 38/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.3996 - accuracy: 0.7746\n",
      "Epoch 39/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.4048 - accuracy: 0.7776\n",
      "Epoch 40/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.3887 - accuracy: 0.7804\n",
      "Epoch 41/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.3699 - accuracy: 0.7994\n",
      "Epoch 42/600\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.3903 - accuracy: 0.7869\n",
      "Epoch 43/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.3520 - accuracy: 0.8131\n",
      "Epoch 44/600\n",
      "110/110 [==============================] - 9s 85ms/step - loss: 0.3547 - accuracy: 0.8099\n",
      "Epoch 45/600\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.3567 - accuracy: 0.8100\n",
      "Epoch 46/600\n",
      "110/110 [==============================] - 7s 62ms/step - loss: 0.3471 - accuracy: 0.8239\n",
      "Epoch 47/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.3748 - accuracy: 0.8014\n",
      "Epoch 48/600\n",
      "110/110 [==============================] - 7s 59ms/step - loss: 0.3460 - accuracy: 0.8180\n",
      "Epoch 49/600\n",
      "110/110 [==============================] - 7s 64ms/step - loss: 0.3528 - accuracy: 0.8281\n",
      "Epoch 50/600\n",
      "110/110 [==============================] - 7s 65ms/step - loss: 0.3150 - accuracy: 0.8379\n",
      "Epoch 51/600\n",
      "110/110 [==============================] - 8s 72ms/step - loss: 0.3493 - accuracy: 0.8214\n",
      "Epoch 52/600\n",
      "110/110 [==============================] - 9s 83ms/step - loss: 0.3675 - accuracy: 0.8083\n",
      "Epoch 53/600\n",
      "110/110 [==============================] - 8s 70ms/step - loss: 0.3270 - accuracy: 0.8374\n",
      "Epoch 54/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.3366 - accuracy: 0.8309\n",
      "Epoch 55/600\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 0.3300 - accuracy: 0.8340\n",
      "Epoch 56/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.3016 - accuracy: 0.8484\n",
      "Epoch 57/600\n",
      "110/110 [==============================] - 9s 84ms/step - loss: 0.3172 - accuracy: 0.8470\n",
      "Epoch 58/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.3070 - accuracy: 0.8456\n",
      "Epoch 59/600\n",
      "110/110 [==============================] - 9s 84ms/step - loss: 0.2909 - accuracy: 0.8576\n",
      "Epoch 60/600\n",
      "110/110 [==============================] - 8s 71ms/step - loss: 0.2981 - accuracy: 0.8541\n",
      "Epoch 61/600\n",
      "110/110 [==============================] - 8s 75ms/step - loss: 0.3165 - accuracy: 0.8489\n",
      "Epoch 62/600\n",
      "110/110 [==============================] - 8s 76ms/step - loss: 0.2824 - accuracy: 0.8683\n",
      "Epoch 63/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.2881 - accuracy: 0.8624\n",
      "Epoch 64/600\n",
      "110/110 [==============================] - 9s 82ms/step - loss: 0.3080 - accuracy: 0.8524\n",
      "Epoch 65/600\n",
      "110/110 [==============================] - 15s 132ms/step - loss: 0.3098 - accuracy: 0.8526\n",
      "Epoch 66/600\n",
      "110/110 [==============================] - 13s 116ms/step - loss: 0.2781 - accuracy: 0.8727\n",
      "Epoch 67/600\n",
      "110/110 [==============================] - 14s 126ms/step - loss: 0.2921 - accuracy: 0.8606\n",
      "Epoch 68/600\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.2744 - accuracy: 0.8719\n",
      "Epoch 69/600\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.2680 - accuracy: 0.8774\n",
      "Epoch 70/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.2886 - accuracy: 0.8659\n",
      "Epoch 71/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2574 - accuracy: 0.8821\n",
      "Epoch 72/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2765 - accuracy: 0.8691\n",
      "Epoch 73/600\n",
      "110/110 [==============================] - 11s 105ms/step - loss: 0.2789 - accuracy: 0.8706\n",
      "Epoch 74/600\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 0.2551 - accuracy: 0.8784\n",
      "Epoch 75/600\n",
      "110/110 [==============================] - 14s 130ms/step - loss: 0.2664 - accuracy: 0.8790\n",
      "Epoch 76/600\n",
      "110/110 [==============================] - 12s 108ms/step - loss: 0.2627 - accuracy: 0.8830\n",
      "Epoch 77/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2653 - accuracy: 0.8817\n",
      "Epoch 78/600\n",
      "110/110 [==============================] - 12s 110ms/step - loss: 0.2619 - accuracy: 0.8813\n",
      "Epoch 79/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 12s 105ms/step - loss: 0.2400 - accuracy: 0.8910\n",
      "Epoch 80/600\n",
      "110/110 [==============================] - 13s 117ms/step - loss: 0.2278 - accuracy: 0.8974\n",
      "Epoch 81/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2312 - accuracy: 0.9027\n",
      "Epoch 82/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2420 - accuracy: 0.8937\n",
      "Epoch 83/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.2345 - accuracy: 0.8959\n",
      "Epoch 84/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2248 - accuracy: 0.9070\n",
      "Epoch 85/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2269 - accuracy: 0.9031\n",
      "Epoch 86/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2254 - accuracy: 0.9000\n",
      "Epoch 87/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2369 - accuracy: 0.9006\n",
      "Epoch 88/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2567 - accuracy: 0.8856\n",
      "Epoch 89/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2237 - accuracy: 0.9064\n",
      "Epoch 90/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2195 - accuracy: 0.9044\n",
      "Epoch 91/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2213 - accuracy: 0.9073\n",
      "Epoch 92/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2203 - accuracy: 0.9047\n",
      "Epoch 93/600\n",
      "110/110 [==============================] - 11s 95ms/step - loss: 0.2030 - accuracy: 0.9136\n",
      "Epoch 94/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2125 - accuracy: 0.9087\n",
      "Epoch 95/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2276 - accuracy: 0.9017\n",
      "Epoch 96/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2209 - accuracy: 0.9059\n",
      "Epoch 97/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2132 - accuracy: 0.9101\n",
      "Epoch 98/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2259 - accuracy: 0.9057\n",
      "Epoch 99/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2224 - accuracy: 0.9063\n",
      "Epoch 100/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2065 - accuracy: 0.9120\n",
      "Epoch 101/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2125 - accuracy: 0.9094\n",
      "Epoch 102/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2198 - accuracy: 0.9074\n",
      "Epoch 103/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2016 - accuracy: 0.9163\n",
      "Epoch 104/600\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.2273 - accuracy: 0.9016\n",
      "Epoch 105/600\n",
      "110/110 [==============================] - 12s 113ms/step - loss: 0.2064 - accuracy: 0.9130\n",
      "Epoch 106/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2345 - accuracy: 0.8971\n",
      "Epoch 107/600\n",
      "110/110 [==============================] - 11s 105ms/step - loss: 0.2108 - accuracy: 0.9089\n",
      "Epoch 108/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.2081 - accuracy: 0.9160\n",
      "Epoch 109/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.2492 - accuracy: 0.8933\n",
      "Epoch 110/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.2061 - accuracy: 0.9150\n",
      "Epoch 111/600\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.2233 - accuracy: 0.9073\n",
      "Epoch 112/600\n",
      "110/110 [==============================] - 13s 114ms/step - loss: 0.2177 - accuracy: 0.9106\n",
      "Epoch 113/600\n",
      "110/110 [==============================] - 9s 86ms/step - loss: 0.2013 - accuracy: 0.9139\n",
      "Epoch 114/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.1985 - accuracy: 0.9146\n",
      "Epoch 115/600\n",
      "110/110 [==============================] - 9s 83ms/step - loss: 0.2149 - accuracy: 0.9063\n",
      "Epoch 116/600\n",
      "110/110 [==============================] - 8s 74ms/step - loss: 0.2278 - accuracy: 0.9027\n",
      "Epoch 117/600\n",
      "110/110 [==============================] - 8s 73ms/step - loss: 0.2094 - accuracy: 0.9089\n",
      "Epoch 118/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.1978 - accuracy: 0.9129\n",
      "Epoch 119/600\n",
      "110/110 [==============================] - 7s 67ms/step - loss: 0.1996 - accuracy: 0.9167\n",
      "Epoch 120/600\n",
      "110/110 [==============================] - 8s 69ms/step - loss: 0.2021 - accuracy: 0.9139\n",
      "Epoch 121/600\n",
      "110/110 [==============================] - 7s 66ms/step - loss: 0.2011 - accuracy: 0.9193\n",
      "Epoch 122/600\n",
      "110/110 [==============================] - 7s 68ms/step - loss: 0.1909 - accuracy: 0.9170\n",
      "Epoch 123/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2209 - accuracy: 0.9097\n",
      "Epoch 124/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2238 - accuracy: 0.9084\n",
      "Epoch 125/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2025 - accuracy: 0.9141\n",
      "Epoch 126/600\n",
      "110/110 [==============================] - 12s 111ms/step - loss: 0.2030 - accuracy: 0.9149\n",
      "Epoch 127/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2266 - accuracy: 0.9080\n",
      "Epoch 128/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.1956 - accuracy: 0.9121\n",
      "Epoch 129/600\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.2180 - accuracy: 0.9083\n",
      "Epoch 130/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.2291 - accuracy: 0.9057\n",
      "Epoch 131/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1991 - accuracy: 0.9124\n",
      "Epoch 132/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2114 - accuracy: 0.9107\n",
      "Epoch 133/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.2040 - accuracy: 0.9153\n",
      "Epoch 134/600\n",
      "110/110 [==============================] - 12s 104ms/step - loss: 0.2112 - accuracy: 0.9096\n",
      "Epoch 135/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2049 - accuracy: 0.9147\n",
      "Epoch 136/600\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.2007 - accuracy: 0.9157\n",
      "Epoch 137/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.2058 - accuracy: 0.9123\n",
      "Epoch 138/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2137 - accuracy: 0.9104\n",
      "Epoch 139/600\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 0.2004 - accuracy: 0.9149\n",
      "Epoch 140/600\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.1872 - accuracy: 0.9221\n",
      "Epoch 141/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1982 - accuracy: 0.9161\n",
      "Epoch 142/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1933 - accuracy: 0.9209\n",
      "Epoch 143/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.2115 - accuracy: 0.9113\n",
      "Epoch 144/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1923 - accuracy: 0.9171\n",
      "Epoch 145/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1950 - accuracy: 0.9181\n",
      "Epoch 146/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2159 - accuracy: 0.9087\n",
      "Epoch 147/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.1962 - accuracy: 0.9164\n",
      "Epoch 148/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.1981 - accuracy: 0.9136\n",
      "Epoch 149/600\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.2034 - accuracy: 0.9140\n",
      "Epoch 150/600\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 0.2013 - accuracy: 0.9183\n",
      "Epoch 151/600\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.1843 - accuracy: 0.9210\n",
      "Epoch 152/600\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.2094 - accuracy: 0.9100\n",
      "Epoch 153/600\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 0.1983 - accuracy: 0.9120\n",
      "Epoch 154/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.1932 - accuracy: 0.9164\n",
      "Epoch 155/600\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.1985 - accuracy: 0.9154\n",
      "Epoch 156/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.1843 - accuracy: 0.9227\n",
      "Epoch 157/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 12s 105ms/step - loss: 0.2036 - accuracy: 0.9129\n",
      "Epoch 158/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.2188 - accuracy: 0.9071\n",
      "Epoch 159/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.1964 - accuracy: 0.9164\n",
      "Epoch 160/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.2303 - accuracy: 0.9016\n",
      "Epoch 161/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2093 - accuracy: 0.9149\n",
      "Epoch 162/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.2170 - accuracy: 0.9116\n",
      "Epoch 163/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1929 - accuracy: 0.9219\n",
      "Epoch 164/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2113 - accuracy: 0.9087\n",
      "Epoch 165/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.1929 - accuracy: 0.9186\n",
      "Epoch 166/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.2122 - accuracy: 0.9113\n",
      "Epoch 167/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.2074 - accuracy: 0.9114\n",
      "Epoch 168/600\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 0.2056 - accuracy: 0.9137\n",
      "Epoch 169/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1887 - accuracy: 0.9200\n",
      "Epoch 170/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2094 - accuracy: 0.9111\n",
      "Epoch 171/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1946 - accuracy: 0.9173\n",
      "Epoch 172/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1967 - accuracy: 0.9153\n",
      "Epoch 173/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1951 - accuracy: 0.9194\n",
      "Epoch 174/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2110 - accuracy: 0.9137\n",
      "Epoch 175/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1929 - accuracy: 0.9177\n",
      "Epoch 176/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1995 - accuracy: 0.9136\n",
      "Epoch 177/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2115 - accuracy: 0.9131\n",
      "Epoch 178/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1968 - accuracy: 0.9161\n",
      "Epoch 179/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1871 - accuracy: 0.9207\n",
      "Epoch 180/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2103 - accuracy: 0.9106\n",
      "Epoch 181/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2125 - accuracy: 0.9087\n",
      "Epoch 182/600\n",
      "110/110 [==============================] - 12s 105ms/step - loss: 0.1906 - accuracy: 0.9181\n",
      "Epoch 183/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.2018 - accuracy: 0.9156\n",
      "Epoch 184/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2038 - accuracy: 0.9123\n",
      "Epoch 185/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2038 - accuracy: 0.9129\n",
      "Epoch 186/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.1942 - accuracy: 0.9201\n",
      "Epoch 187/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1986 - accuracy: 0.9127\n",
      "Epoch 188/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1880 - accuracy: 0.9190\n",
      "Epoch 189/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2161 - accuracy: 0.9096\n",
      "Epoch 190/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1784 - accuracy: 0.9223\n",
      "Epoch 191/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2022 - accuracy: 0.9131\n",
      "Epoch 192/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1952 - accuracy: 0.9190\n",
      "Epoch 193/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1946 - accuracy: 0.9157\n",
      "Epoch 194/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2060 - accuracy: 0.9103\n",
      "Epoch 195/600\n",
      "110/110 [==============================] - 12s 106ms/step - loss: 0.2130 - accuracy: 0.9087\n",
      "Epoch 196/600\n",
      "110/110 [==============================] - 11s 104ms/step - loss: 0.2198 - accuracy: 0.9079\n",
      "Epoch 197/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.2014 - accuracy: 0.9146\n",
      "Epoch 198/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2013 - accuracy: 0.9134\n",
      "Epoch 199/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1948 - accuracy: 0.9177\n",
      "Epoch 200/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2080 - accuracy: 0.9111\n",
      "Epoch 201/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.2109 - accuracy: 0.9120\n",
      "Epoch 202/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1954 - accuracy: 0.9199\n",
      "Epoch 203/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.2102 - accuracy: 0.9160\n",
      "Epoch 204/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1809 - accuracy: 0.9251\n",
      "Epoch 205/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1866 - accuracy: 0.9201\n",
      "Epoch 206/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1964 - accuracy: 0.9189\n",
      "Epoch 207/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2024 - accuracy: 0.9139\n",
      "Epoch 208/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2032 - accuracy: 0.9149\n",
      "Epoch 209/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1878 - accuracy: 0.9186\n",
      "Epoch 210/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2105 - accuracy: 0.9130\n",
      "Epoch 211/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1756 - accuracy: 0.9259\n",
      "Epoch 212/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2160 - accuracy: 0.9067\n",
      "Epoch 213/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1843 - accuracy: 0.9206\n",
      "Epoch 214/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1979 - accuracy: 0.9146\n",
      "Epoch 215/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1988 - accuracy: 0.9114\n",
      "Epoch 216/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1951 - accuracy: 0.9161\n",
      "Epoch 217/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2001 - accuracy: 0.9141\n",
      "Epoch 218/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2030 - accuracy: 0.9123\n",
      "Epoch 219/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2041 - accuracy: 0.9104\n",
      "Epoch 220/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1970 - accuracy: 0.9169\n",
      "Epoch 221/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1942 - accuracy: 0.9209\n",
      "Epoch 222/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1947 - accuracy: 0.9147\n",
      "Epoch 223/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1941 - accuracy: 0.9190\n",
      "Epoch 224/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2070 - accuracy: 0.9091\n",
      "Epoch 225/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2006 - accuracy: 0.9181\n",
      "Epoch 226/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1989 - accuracy: 0.9183\n",
      "Epoch 227/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2051 - accuracy: 0.9123\n",
      "Epoch 228/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1995 - accuracy: 0.9167\n",
      "Epoch 229/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1907 - accuracy: 0.9149\n",
      "Epoch 230/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2051 - accuracy: 0.9134\n",
      "Epoch 231/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1979 - accuracy: 0.9167\n",
      "Epoch 232/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2066 - accuracy: 0.9139\n",
      "Epoch 233/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2042 - accuracy: 0.9133\n",
      "Epoch 234/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1950 - accuracy: 0.9189\n",
      "Epoch 235/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2142 - accuracy: 0.9087\n",
      "Epoch 236/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1939 - accuracy: 0.9217\n",
      "Epoch 237/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1916 - accuracy: 0.9161\n",
      "Epoch 238/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2091 - accuracy: 0.9097\n",
      "Epoch 239/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1801 - accuracy: 0.9240\n",
      "Epoch 240/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2051 - accuracy: 0.9119\n",
      "Epoch 241/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1825 - accuracy: 0.9227\n",
      "Epoch 242/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1942 - accuracy: 0.9181\n",
      "Epoch 243/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1834 - accuracy: 0.9196\n",
      "Epoch 244/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1813 - accuracy: 0.9247\n",
      "Epoch 245/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1932 - accuracy: 0.9193\n",
      "Epoch 246/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1871 - accuracy: 0.9243\n",
      "Epoch 247/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1987 - accuracy: 0.9163\n",
      "Epoch 248/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1967 - accuracy: 0.9154\n",
      "Epoch 249/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1940 - accuracy: 0.9167\n",
      "Epoch 250/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1965 - accuracy: 0.9146\n",
      "Epoch 251/600\n",
      "110/110 [==============================] - 11s 95ms/step - loss: 0.1996 - accuracy: 0.9176\n",
      "Epoch 252/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1945 - accuracy: 0.9189\n",
      "Epoch 253/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1979 - accuracy: 0.9140\n",
      "Epoch 254/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.2095 - accuracy: 0.9096\n",
      "Epoch 255/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1764 - accuracy: 0.9229\n",
      "Epoch 256/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2027 - accuracy: 0.9141\n",
      "Epoch 257/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1932 - accuracy: 0.9177\n",
      "Epoch 258/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2017 - accuracy: 0.9157\n",
      "Epoch 259/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2094 - accuracy: 0.9140\n",
      "Epoch 260/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1715 - accuracy: 0.9257\n",
      "Epoch 261/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1877 - accuracy: 0.9223\n",
      "Epoch 262/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1945 - accuracy: 0.9154\n",
      "Epoch 263/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1979 - accuracy: 0.9166\n",
      "Epoch 264/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2067 - accuracy: 0.9111\n",
      "Epoch 265/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1908 - accuracy: 0.9179\n",
      "Epoch 266/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1859 - accuracy: 0.9237\n",
      "Epoch 267/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1910 - accuracy: 0.9194\n",
      "Epoch 268/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2016 - accuracy: 0.9170\n",
      "Epoch 269/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1883 - accuracy: 0.9160\n",
      "Epoch 270/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1872 - accuracy: 0.9174\n",
      "Epoch 271/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1914 - accuracy: 0.9179\n",
      "Epoch 272/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1938 - accuracy: 0.9171\n",
      "Epoch 273/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2003 - accuracy: 0.9127\n",
      "Epoch 274/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1947 - accuracy: 0.9150\n",
      "Epoch 275/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1880 - accuracy: 0.9183\n",
      "Epoch 276/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1945 - accuracy: 0.9137\n",
      "Epoch 277/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2058 - accuracy: 0.9089\n",
      "Epoch 278/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2010 - accuracy: 0.9144\n",
      "Epoch 279/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1775 - accuracy: 0.9244\n",
      "Epoch 280/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1956 - accuracy: 0.9166\n",
      "Epoch 281/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2070 - accuracy: 0.9120\n",
      "Epoch 282/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1860 - accuracy: 0.9224\n",
      "Epoch 283/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2066 - accuracy: 0.9109\n",
      "Epoch 284/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1888 - accuracy: 0.9183\n",
      "Epoch 285/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.2291 - accuracy: 0.9049\n",
      "Epoch 286/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2013 - accuracy: 0.9119\n",
      "Epoch 287/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1879 - accuracy: 0.9177\n",
      "Epoch 288/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1954 - accuracy: 0.9150\n",
      "Epoch 289/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1934 - accuracy: 0.9150\n",
      "Epoch 290/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2040 - accuracy: 0.9110\n",
      "Epoch 291/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2047 - accuracy: 0.9109\n",
      "Epoch 292/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1861 - accuracy: 0.9219\n",
      "Epoch 293/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2292 - accuracy: 0.9041\n",
      "Epoch 294/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.2020 - accuracy: 0.9167\n",
      "Epoch 295/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2121 - accuracy: 0.9043\n",
      "Epoch 296/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1960 - accuracy: 0.9147\n",
      "Epoch 297/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.2233 - accuracy: 0.9010\n",
      "Epoch 298/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.2026 - accuracy: 0.9161\n",
      "Epoch 299/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2058 - accuracy: 0.9126\n",
      "Epoch 300/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2099 - accuracy: 0.9117\n",
      "Epoch 301/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2156 - accuracy: 0.9090\n",
      "Epoch 302/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2022 - accuracy: 0.9129\n",
      "Epoch 303/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1967 - accuracy: 0.9159\n",
      "Epoch 304/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1895 - accuracy: 0.9157\n",
      "Epoch 305/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1851 - accuracy: 0.9189\n",
      "Epoch 306/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2138 - accuracy: 0.9111\n",
      "Epoch 307/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2008 - accuracy: 0.9103\n",
      "Epoch 308/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1955 - accuracy: 0.9171\n",
      "Epoch 309/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2024 - accuracy: 0.9090\n",
      "Epoch 310/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1960 - accuracy: 0.9166\n",
      "Epoch 311/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1879 - accuracy: 0.9217\n",
      "Epoch 312/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1870 - accuracy: 0.9184\n",
      "Epoch 313/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2024 - accuracy: 0.9130\n",
      "Epoch 314/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1858 - accuracy: 0.9186\n",
      "Epoch 315/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1879 - accuracy: 0.9200\n",
      "Epoch 316/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1910 - accuracy: 0.9186\n",
      "Epoch 317/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2113 - accuracy: 0.9143\n",
      "Epoch 318/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1866 - accuracy: 0.9199\n",
      "Epoch 319/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1992 - accuracy: 0.9133\n",
      "Epoch 320/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1831 - accuracy: 0.9210\n",
      "Epoch 321/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1862 - accuracy: 0.9209\n",
      "Epoch 322/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2044 - accuracy: 0.9077\n",
      "Epoch 323/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1992 - accuracy: 0.9134\n",
      "Epoch 324/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.2026 - accuracy: 0.9170\n",
      "Epoch 325/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1976 - accuracy: 0.9176\n",
      "Epoch 326/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1878 - accuracy: 0.9193\n",
      "Epoch 327/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1781 - accuracy: 0.9236\n",
      "Epoch 328/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1867 - accuracy: 0.9170\n",
      "Epoch 329/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1862 - accuracy: 0.9207\n",
      "Epoch 330/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1934 - accuracy: 0.9196\n",
      "Epoch 331/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1970 - accuracy: 0.9159\n",
      "Epoch 332/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1842 - accuracy: 0.9234\n",
      "Epoch 333/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1890 - accuracy: 0.9173\n",
      "Epoch 334/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1924 - accuracy: 0.9199\n",
      "Epoch 335/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1940 - accuracy: 0.9216\n",
      "Epoch 336/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.2035 - accuracy: 0.9133\n",
      "Epoch 337/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1965 - accuracy: 0.9204\n",
      "Epoch 338/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1961 - accuracy: 0.9140\n",
      "Epoch 339/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1968 - accuracy: 0.9161\n",
      "Epoch 340/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1930 - accuracy: 0.9179\n",
      "Epoch 341/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1849 - accuracy: 0.9243\n",
      "Epoch 342/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1937 - accuracy: 0.9160\n",
      "Epoch 343/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1850 - accuracy: 0.9211\n",
      "Epoch 344/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1975 - accuracy: 0.9176\n",
      "Epoch 345/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1759 - accuracy: 0.9239\n",
      "Epoch 346/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2001 - accuracy: 0.9144\n",
      "Epoch 347/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1909 - accuracy: 0.9209\n",
      "Epoch 348/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1899 - accuracy: 0.9230\n",
      "Epoch 349/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1872 - accuracy: 0.9224\n",
      "Epoch 350/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1865 - accuracy: 0.9226\n",
      "Epoch 351/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1962 - accuracy: 0.9191\n",
      "Epoch 352/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1898 - accuracy: 0.9197\n",
      "Epoch 353/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1968 - accuracy: 0.9157\n",
      "Epoch 354/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1911 - accuracy: 0.9190\n",
      "Epoch 355/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2027 - accuracy: 0.9096\n",
      "Epoch 356/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.2104 - accuracy: 0.9096\n",
      "Epoch 357/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2023 - accuracy: 0.9127\n",
      "Epoch 358/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1790 - accuracy: 0.9267\n",
      "Epoch 359/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1860 - accuracy: 0.9196\n",
      "Epoch 360/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1968 - accuracy: 0.9151\n",
      "Epoch 361/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1815 - accuracy: 0.9220\n",
      "Epoch 362/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2027 - accuracy: 0.9149\n",
      "Epoch 363/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1943 - accuracy: 0.9169\n",
      "Epoch 364/600\n",
      "110/110 [==============================] - 12s 107ms/step - loss: 0.1997 - accuracy: 0.9139\n",
      "Epoch 365/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1881 - accuracy: 0.9217\n",
      "Epoch 366/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1801 - accuracy: 0.9244\n",
      "Epoch 367/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1778 - accuracy: 0.9233\n",
      "Epoch 368/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1909 - accuracy: 0.9197\n",
      "Epoch 369/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2209 - accuracy: 0.9010\n",
      "Epoch 370/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1935 - accuracy: 0.9157\n",
      "Epoch 371/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1898 - accuracy: 0.9191\n",
      "Epoch 372/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1865 - accuracy: 0.9200\n",
      "Epoch 373/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1968 - accuracy: 0.9144\n",
      "Epoch 374/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1985 - accuracy: 0.9179\n",
      "Epoch 375/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1950 - accuracy: 0.9163\n",
      "Epoch 376/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1977 - accuracy: 0.9143\n",
      "Epoch 377/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1917 - accuracy: 0.9180\n",
      "Epoch 378/600\n",
      "110/110 [==============================] - 11s 95ms/step - loss: 0.1992 - accuracy: 0.9099\n",
      "Epoch 379/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.2016 - accuracy: 0.9173\n",
      "Epoch 380/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2030 - accuracy: 0.9117\n",
      "Epoch 381/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1745 - accuracy: 0.9254\n",
      "Epoch 382/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1818 - accuracy: 0.9213\n",
      "Epoch 383/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1921 - accuracy: 0.9147\n",
      "Epoch 384/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1955 - accuracy: 0.9164\n",
      "Epoch 385/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1720 - accuracy: 0.9256\n",
      "Epoch 386/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1959 - accuracy: 0.9111\n",
      "Epoch 387/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2048 - accuracy: 0.9094\n",
      "Epoch 388/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1848 - accuracy: 0.9206\n",
      "Epoch 389/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1951 - accuracy: 0.9191\n",
      "Epoch 390/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2048 - accuracy: 0.9110\n",
      "Epoch 391/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1889 - accuracy: 0.9200\n",
      "Epoch 392/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2022 - accuracy: 0.9200\n",
      "Epoch 393/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1963 - accuracy: 0.9141\n",
      "Epoch 394/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1858 - accuracy: 0.9187\n",
      "Epoch 395/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1973 - accuracy: 0.9146\n",
      "Epoch 396/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1919 - accuracy: 0.9210\n",
      "Epoch 397/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.2119 - accuracy: 0.9080\n",
      "Epoch 398/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1906 - accuracy: 0.9156\n",
      "Epoch 399/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1890 - accuracy: 0.9234\n",
      "Epoch 400/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1842 - accuracy: 0.9200\n",
      "Epoch 401/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1931 - accuracy: 0.9174\n",
      "Epoch 402/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1858 - accuracy: 0.9269\n",
      "Epoch 403/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1951 - accuracy: 0.9170\n",
      "Epoch 404/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1814 - accuracy: 0.9227\n",
      "Epoch 405/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1937 - accuracy: 0.9189\n",
      "Epoch 406/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1942 - accuracy: 0.9177\n",
      "Epoch 407/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1808 - accuracy: 0.9197\n",
      "Epoch 408/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2064 - accuracy: 0.9113\n",
      "Epoch 409/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2114 - accuracy: 0.9117\n",
      "Epoch 410/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1866 - accuracy: 0.9191\n",
      "Epoch 411/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2129 - accuracy: 0.9113\n",
      "Epoch 412/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1857 - accuracy: 0.9214\n",
      "Epoch 413/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1917 - accuracy: 0.9164\n",
      "Epoch 414/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1971 - accuracy: 0.9127\n",
      "Epoch 415/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1768 - accuracy: 0.9206\n",
      "Epoch 416/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1999 - accuracy: 0.9111\n",
      "Epoch 417/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1834 - accuracy: 0.9219\n",
      "Epoch 418/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1838 - accuracy: 0.9216\n",
      "Epoch 419/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1843 - accuracy: 0.9194\n",
      "Epoch 420/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1864 - accuracy: 0.9209\n",
      "Epoch 421/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1729 - accuracy: 0.9256\n",
      "Epoch 422/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2137 - accuracy: 0.9129\n",
      "Epoch 423/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1919 - accuracy: 0.9214\n",
      "Epoch 424/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1935 - accuracy: 0.9174\n",
      "Epoch 425/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1847 - accuracy: 0.9206\n",
      "Epoch 426/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1941 - accuracy: 0.9187\n",
      "Epoch 427/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1813 - accuracy: 0.9199\n",
      "Epoch 428/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1873 - accuracy: 0.9209\n",
      "Epoch 429/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1853 - accuracy: 0.9194\n",
      "Epoch 430/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2215 - accuracy: 0.9050\n",
      "Epoch 431/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1973 - accuracy: 0.9170\n",
      "Epoch 432/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1832 - accuracy: 0.9221\n",
      "Epoch 433/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2000 - accuracy: 0.9151\n",
      "Epoch 434/600\n",
      "110/110 [==============================] - 11s 95ms/step - loss: 0.1900 - accuracy: 0.9209\n",
      "Epoch 435/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1925 - accuracy: 0.9183\n",
      "Epoch 436/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1759 - accuracy: 0.9264\n",
      "Epoch 437/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1808 - accuracy: 0.9253\n",
      "Epoch 438/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1965 - accuracy: 0.9133\n",
      "Epoch 439/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1791 - accuracy: 0.9210\n",
      "Epoch 440/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1863 - accuracy: 0.9226\n",
      "Epoch 441/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1913 - accuracy: 0.9174\n",
      "Epoch 442/600\n",
      "110/110 [==============================] - 11s 103ms/step - loss: 0.1866 - accuracy: 0.9200\n",
      "Epoch 443/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1966 - accuracy: 0.9180\n",
      "Epoch 444/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2137 - accuracy: 0.9073\n",
      "Epoch 445/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1890 - accuracy: 0.9221\n",
      "Epoch 446/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1889 - accuracy: 0.9169\n",
      "Epoch 447/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1956 - accuracy: 0.9191\n",
      "Epoch 448/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1806 - accuracy: 0.9210\n",
      "Epoch 449/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1902 - accuracy: 0.9151\n",
      "Epoch 450/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1932 - accuracy: 0.9181\n",
      "Epoch 451/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1978 - accuracy: 0.9164\n",
      "Epoch 452/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2045 - accuracy: 0.9116\n",
      "Epoch 453/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1824 - accuracy: 0.9206\n",
      "Epoch 454/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1753 - accuracy: 0.9263\n",
      "Epoch 455/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1907 - accuracy: 0.9204\n",
      "Epoch 456/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1992 - accuracy: 0.9166\n",
      "Epoch 457/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1864 - accuracy: 0.9189\n",
      "Epoch 458/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1808 - accuracy: 0.9209\n",
      "Epoch 459/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1936 - accuracy: 0.9156\n",
      "Epoch 460/600\n",
      "110/110 [==============================] - 12s 109ms/step - loss: 0.1916 - accuracy: 0.9189\n",
      "Epoch 461/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1816 - accuracy: 0.9197\n",
      "Epoch 462/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1874 - accuracy: 0.9220\n",
      "Epoch 463/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1958 - accuracy: 0.9153\n",
      "Epoch 464/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1825 - accuracy: 0.9201\n",
      "Epoch 465/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1844 - accuracy: 0.9209\n",
      "Epoch 466/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1953 - accuracy: 0.9149\n",
      "Epoch 467/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.2058 - accuracy: 0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1847 - accuracy: 0.9227\n",
      "Epoch 469/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1880 - accuracy: 0.9166\n",
      "Epoch 470/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.2079 - accuracy: 0.9091\n",
      "Epoch 471/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1897 - accuracy: 0.9179\n",
      "Epoch 472/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1933 - accuracy: 0.9187\n",
      "Epoch 473/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1874 - accuracy: 0.9193\n",
      "Epoch 474/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1914 - accuracy: 0.9159\n",
      "Epoch 475/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1928 - accuracy: 0.9136\n",
      "Epoch 476/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1941 - accuracy: 0.9150\n",
      "Epoch 477/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2302 - accuracy: 0.8964\n",
      "Epoch 478/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1975 - accuracy: 0.9170\n",
      "Epoch 479/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2044 - accuracy: 0.9149\n",
      "Epoch 480/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1802 - accuracy: 0.9241\n",
      "Epoch 481/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1983 - accuracy: 0.9190\n",
      "Epoch 482/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1981 - accuracy: 0.9147\n",
      "Epoch 483/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1909 - accuracy: 0.9190\n",
      "Epoch 484/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1818 - accuracy: 0.9194\n",
      "Epoch 485/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1980 - accuracy: 0.9157\n",
      "Epoch 486/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1807 - accuracy: 0.9244\n",
      "Epoch 487/600\n",
      "110/110 [==============================] - 9s 85ms/step - loss: 0.1756 - accuracy: 0.9231\n",
      "Epoch 488/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.2067 - accuracy: 0.9134\n",
      "Epoch 489/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.2044 - accuracy: 0.9166\n",
      "Epoch 490/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1865 - accuracy: 0.9201\n",
      "Epoch 491/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1906 - accuracy: 0.9180\n",
      "Epoch 492/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1963 - accuracy: 0.9103\n",
      "Epoch 493/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1984 - accuracy: 0.9191\n",
      "Epoch 494/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1881 - accuracy: 0.9209\n",
      "Epoch 495/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2089 - accuracy: 0.9146\n",
      "Epoch 496/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1871 - accuracy: 0.9204\n",
      "Epoch 497/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1939 - accuracy: 0.9179\n",
      "Epoch 498/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1906 - accuracy: 0.9181\n",
      "Epoch 499/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.2224 - accuracy: 0.9031\n",
      "Epoch 500/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1796 - accuracy: 0.9253\n",
      "Epoch 501/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1938 - accuracy: 0.9180\n",
      "Epoch 502/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.2092 - accuracy: 0.9063\n",
      "Epoch 503/600\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.1794 - accuracy: 0.9229\n",
      "Epoch 504/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1851 - accuracy: 0.9216\n",
      "Epoch 505/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1946 - accuracy: 0.9209\n",
      "Epoch 506/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1818 - accuracy: 0.9200\n",
      "Epoch 507/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1918 - accuracy: 0.9201\n",
      "Epoch 508/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.2006 - accuracy: 0.9144\n",
      "Epoch 509/600\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.1794 - accuracy: 0.9250\n",
      "Epoch 510/600\n",
      "110/110 [==============================] - 9s 85ms/step - loss: 0.2010 - accuracy: 0.9140\n",
      "Epoch 511/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.2053 - accuracy: 0.9167\n",
      "Epoch 512/600\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.2038 - accuracy: 0.9153\n",
      "Epoch 513/600\n",
      "110/110 [==============================] - 9s 86ms/step - loss: 0.2102 - accuracy: 0.9116\n",
      "Epoch 514/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.2024 - accuracy: 0.9183\n",
      "Epoch 515/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.2063 - accuracy: 0.9151\n",
      "Epoch 516/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1836 - accuracy: 0.9213\n",
      "Epoch 517/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.2153 - accuracy: 0.9094\n",
      "Epoch 518/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.2140 - accuracy: 0.9067\n",
      "Epoch 519/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.2065 - accuracy: 0.9100\n",
      "Epoch 520/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1915 - accuracy: 0.9180\n",
      "Epoch 521/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1931 - accuracy: 0.9147\n",
      "Epoch 522/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1651 - accuracy: 0.9300\n",
      "Epoch 523/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1830 - accuracy: 0.9223\n",
      "Epoch 524/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1866 - accuracy: 0.9209\n",
      "Epoch 525/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1807 - accuracy: 0.9251\n",
      "Epoch 526/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1794 - accuracy: 0.9204\n",
      "Epoch 527/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1797 - accuracy: 0.9214\n",
      "Epoch 528/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1864 - accuracy: 0.9187\n",
      "Epoch 529/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1944 - accuracy: 0.9173\n",
      "Epoch 530/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1892 - accuracy: 0.9201\n",
      "Epoch 531/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1714 - accuracy: 0.9257\n",
      "Epoch 532/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1766 - accuracy: 0.9267\n",
      "Epoch 533/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1865 - accuracy: 0.9220\n",
      "Epoch 534/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1747 - accuracy: 0.9249\n",
      "Epoch 535/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1776 - accuracy: 0.9250\n",
      "Epoch 536/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1789 - accuracy: 0.9237\n",
      "Epoch 537/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1798 - accuracy: 0.9219\n",
      "Epoch 538/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1941 - accuracy: 0.9113\n",
      "Epoch 539/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1715 - accuracy: 0.9277\n",
      "Epoch 540/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1944 - accuracy: 0.9141\n",
      "Epoch 541/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1679 - accuracy: 0.9286\n",
      "Epoch 542/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.2102 - accuracy: 0.9134\n",
      "Epoch 543/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.2006 - accuracy: 0.9154\n",
      "Epoch 544/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.2184 - accuracy: 0.9114\n",
      "Epoch 545/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1813 - accuracy: 0.9237\n",
      "Epoch 546/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1981 - accuracy: 0.9160\n",
      "Epoch 547/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1816 - accuracy: 0.9244\n",
      "Epoch 548/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1795 - accuracy: 0.9216\n",
      "Epoch 549/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1784 - accuracy: 0.9214\n",
      "Epoch 550/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.2014 - accuracy: 0.9167\n",
      "Epoch 551/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1854 - accuracy: 0.9191\n",
      "Epoch 552/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1836 - accuracy: 0.9191\n",
      "Epoch 553/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1744 - accuracy: 0.9250\n",
      "Epoch 554/600\n",
      "110/110 [==============================] - 11s 99ms/step - loss: 0.1714 - accuracy: 0.9301\n",
      "Epoch 555/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1845 - accuracy: 0.9183\n",
      "Epoch 556/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.2228 - accuracy: 0.9044\n",
      "Epoch 557/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1748 - accuracy: 0.9289\n",
      "Epoch 558/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1721 - accuracy: 0.9259\n",
      "Epoch 559/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1984 - accuracy: 0.9193\n",
      "Epoch 560/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1836 - accuracy: 0.9224\n",
      "Epoch 561/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1652 - accuracy: 0.9299\n",
      "Epoch 562/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1778 - accuracy: 0.9247\n",
      "Epoch 563/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1893 - accuracy: 0.9203\n",
      "Epoch 564/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.1744 - accuracy: 0.9249\n",
      "Epoch 565/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1818 - accuracy: 0.9211\n",
      "Epoch 566/600\n",
      "110/110 [==============================] - 10s 96ms/step - loss: 0.1873 - accuracy: 0.9229\n",
      "Epoch 567/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1931 - accuracy: 0.9191\n",
      "Epoch 568/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1730 - accuracy: 0.9227\n",
      "Epoch 569/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1882 - accuracy: 0.9201\n",
      "Epoch 570/600\n",
      "110/110 [==============================] - 10s 91ms/step - loss: 0.2014 - accuracy: 0.9144\n",
      "Epoch 571/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.1773 - accuracy: 0.9260\n",
      "Epoch 572/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1881 - accuracy: 0.9206\n",
      "Epoch 573/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1867 - accuracy: 0.9207\n",
      "Epoch 574/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.2131 - accuracy: 0.9113\n",
      "Epoch 575/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1782 - accuracy: 0.9254\n",
      "Epoch 576/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1799 - accuracy: 0.9240\n",
      "Epoch 577/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1840 - accuracy: 0.9221\n",
      "Epoch 578/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1832 - accuracy: 0.9220\n",
      "Epoch 579/600\n",
      "110/110 [==============================] - 11s 98ms/step - loss: 0.1926 - accuracy: 0.9187\n",
      "Epoch 580/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.1781 - accuracy: 0.9233\n",
      "Epoch 581/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.2394 - accuracy: 0.9021\n",
      "Epoch 582/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.2008 - accuracy: 0.9193\n",
      "Epoch 583/600\n",
      "110/110 [==============================] - 10s 93ms/step - loss: 0.1839 - accuracy: 0.9206\n",
      "Epoch 584/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1900 - accuracy: 0.9241\n",
      "Epoch 585/600\n",
      "110/110 [==============================] - 10s 92ms/step - loss: 0.2022 - accuracy: 0.9131\n",
      "Epoch 586/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1873 - accuracy: 0.9201\n",
      "Epoch 587/600\n",
      "110/110 [==============================] - 10s 89ms/step - loss: 0.1833 - accuracy: 0.9229\n",
      "Epoch 588/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1978 - accuracy: 0.9133\n",
      "Epoch 589/600\n",
      "110/110 [==============================] - 11s 96ms/step - loss: 0.2221 - accuracy: 0.9064\n",
      "Epoch 590/600\n",
      "110/110 [==============================] - 10s 95ms/step - loss: 0.1943 - accuracy: 0.9180\n",
      "Epoch 591/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1879 - accuracy: 0.9200\n",
      "Epoch 592/600\n",
      "110/110 [==============================] - 10s 90ms/step - loss: 0.1871 - accuracy: 0.9189\n",
      "Epoch 593/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1770 - accuracy: 0.9223\n",
      "Epoch 594/600\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.1771 - accuracy: 0.9231\n",
      "Epoch 595/600\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 0.1769 - accuracy: 0.9231\n",
      "Epoch 596/600\n",
      "110/110 [==============================] - 11s 101ms/step - loss: 0.1867 - accuracy: 0.9226\n",
      "Epoch 597/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1957 - accuracy: 0.9113\n",
      "Epoch 598/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.1888 - accuracy: 0.9196\n",
      "Epoch 599/600\n",
      "110/110 [==============================] - 11s 100ms/step - loss: 0.1701 - accuracy: 0.9286\n",
      "Epoch 600/600\n",
      "110/110 [==============================] - 11s 102ms/step - loss: 0.2006 - accuracy: 0.9151\n",
      "94/94 [==============================] - 6s 25ms/step - loss: 0.2401 - accuracy: 0.9057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24007077515125275, 0.9056666493415833]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmodel.compile(loss='binary_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "            )\n",
    "qmodel.fit(x_train, y_train, batch_size=64, epochs=600)\n",
    "qmodel.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
